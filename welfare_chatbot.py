import time
import re
import os

import streamlit as st
from streamlit_chatbox import *

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.llms import HuggingFacePipeline
from transformers import AutoTokenizer, pipeline
import torch
from langchain.schema import Document
from typing import List
import unicodedata
from kiwipiepy import Kiwi
from langchain_community.vectorstores import FAISS
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever

_kiwi = None

# ì±„íŒ… ëª©ë¡ ê´€ë¦¬ í•¨ìˆ˜
def get_chat_list():
    """ì±„íŒ… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if "chat_list" not in st.session_state:
        st.session_state.chat_list = ["welfare_chat"]
    return st.session_state.chat_list

def add_new_chat():
    """ìƒˆ ì±„íŒ…ì„ ëª©ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    if "chat_list" not in st.session_state:
        st.session_state.chat_list = ["welfare_chat"]
    
    # ìµœëŒ€ ì±„íŒ… ë²ˆí˜¸ ê´€ë¦¬
    if "max_chat_number" not in st.session_state:
        st.session_state.max_chat_number = 0
    
    # ìƒˆ ì±„íŒ… ë²ˆí˜¸ëŠ” í˜„ì¬ ìµœëŒ€ ë²ˆí˜¸ + 1
    st.session_state.max_chat_number += 1
    new_chat_name = f"ìƒˆ ì±„íŒ… {st.session_state.max_chat_number}"
    
    st.session_state.chat_list.append(new_chat_name)
    return new_chat_name

def delete_chat(chat_name):
    """ì±„íŒ…ì„ ëª©ë¡ì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤."""
    if "chat_list" in st.session_state and chat_name in st.session_state.chat_list:
        st.session_state.chat_list.remove(chat_name)
        # ì‚­ì œëœ ì±„íŒ…ì´ í˜„ì¬ ì±„íŒ…ì´ë©´ ì²« ë²ˆì§¸ ì±„íŒ…ìœ¼ë¡œ ë³€ê²½
        if st.session_state.get("current_chat") == chat_name:
            if st.session_state.chat_list:
                st.session_state.current_chat = st.session_state.chat_list[0]
                st.session_state.chat_box.use_chat_name(st.session_state.current_chat)
            else:
                # ëª¨ë“  ì±„íŒ…ì´ ì‚­ì œë˜ë©´ ê¸°ë³¸ ì±„íŒ… ìƒì„±
                st.session_state.chat_list = ["welfare_chat"]
                st.session_state.current_chat = "welfare_chat"
                st.session_state.chat_box.use_chat_name("welfare_chat")

def start_new_chat():
    """ìƒˆ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
    new_chat_name = add_new_chat()
    st.session_state.current_chat = new_chat_name
    st.session_state.chat_box.use_chat_name(new_chat_name)
    st.session_state.chat_box.init_session(clear=True)
    st.session_state.chat_started = False
    st.rerun()

# ìºì‹œ ë©”ëª¨ë¦¬ ê´€ë¦¬ í•¨ìˆ˜
def get_conversation_cache_key(chat_name):
    """ì±„íŒ…ë³„ ëŒ€í™” ìºì‹œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return f"conv_cache_{chat_name}"

def save_conversation_to_cache(chat_name, question, answer):
    """ëŒ€í™”ë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    cache_key = get_conversation_cache_key(chat_name)
    if cache_key not in st.session_state:
        st.session_state[cache_key] = []
    
    st.session_state[cache_key].append({
        "question": question,
        "answer": answer,
        "timestamp": time.time()
    })
    
    # ìµœê·¼ 10ê°œ ëŒ€í™”ë§Œ ìœ ì§€
    if len(st.session_state[cache_key]) > 10:
        st.session_state[cache_key] = st.session_state[cache_key][-10:]

def get_conversation_history(chat_name):
    """ì±„íŒ…ë³„ ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    cache_key = get_conversation_cache_key(chat_name)
    return st.session_state.get(cache_key, [])

def format_conversation_history(chat_name):
    """ëŒ€í™” ê¸°ë¡ì„ í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    history = get_conversation_history(chat_name)
    if not history:
        return ""
    
    formatted_history = "\n[ì´ì „ ëŒ€í™” ê¸°ë¡]:\n"
    for i, conv in enumerate(history[-3:], 1):  # ìµœê·¼ 3ê°œë§Œ ì°¸ì¡° (ì„±ëŠ¥ í–¥ìƒ)
        formatted_history += f"Q{i}: {conv['question']}\n"
        formatted_history += f"A{i}: {conv['answer'][:150]}...\n"  # ë‹µë³€ì€ 150ìë¡œ ì œí•œ
    
    return formatted_history

# ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±° í•¨ìˆ˜
def remove_emojis_and_enclosed_chars(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì´ëª¨ì§€ì™€ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
    return ''.join(
        ch for ch in text
        if not (
            unicodedata.category(ch).startswith('So')
            or (0x1F000 <= ord(ch) <= 0x1FFFF)
            or (0x2460 <= ord(ch) <= 0x24FF)
        )
    )

# ë¬¸ì„œ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_document(text):
    """ë¬¸ì„œì—ì„œ ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´, íƒœê·¸, ì´ëª¨ì§€ ë“±ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
    text = remove_emojis_and_enclosed_chars(text)
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
    text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'(\*\*|\*|_)', '', text)
    text = re.sub(r'^[-\*\+]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\n+', '\n', text).strip()
    return text

# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def process_pages(pages: List[Document]) -> List[Document]:
    """ê° ë¬¸ì„œë¥¼ ì „ì²˜ë¦¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return [Document(page_content=preprocess_document(page.page_content), metadata=page.metadata) for page in pages]

def get_kiwi_instance():
    """Kiwi ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹±ê¸€í†¤ìœ¼ë¡œ ê´€ë¦¬"""
    global _kiwi
    if _kiwi is None:
        _kiwi = Kiwi()
    return _kiwi

def kiwi_tokenize(text):
    """ìµœì í™”ëœ Kiwi í† í°í™” í•¨ìˆ˜"""
    if not text or not text.strip():
        return []
    
    kiwi = get_kiwi_instance()
    try:
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ì„œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
        if len(text) > 1000:
            text = text[:1000]
        
        tokens = kiwi.tokenize(text)
        return [token.form for token in tokens if len(token.form) > 1]  # í•œ ê¸€ì í† í° ì œê±°
    except Exception as e:
        # í† í°í™” ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ê³µë°± ë¶„í• 
        return [word for word in text.split() if len(word) > 1]

# ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
def add_documents_in_batches(vectorstore, documents, batch_size=1000):
    """ë¬¸ì„œë“¤ì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€"""
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i + batch_size]
        vectorstore.add_documents(batch)

# ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
def load_and_process_documents(file_paths: List[str], embedding_model):
    """ì—¬ëŸ¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  EnsembleRetrieverë¥¼ ìƒì„±"""
    try:
        all_documents = []
        successful_files = []
        for file_path in file_paths:
            loader = PyMuPDFLoader(file_path)
            documents = loader.load()
            all_documents.extend(documents)
            successful_files.append(file_path)
        
        if not all_documents:
            return None, None, None
        
        print(f"ì´ {len(all_documents)}ê°œ í˜ì´ì§€ ë¡œë”© ì™„ë£Œ")
        
        processed_data = process_pages(all_documents)
        
        processed_data = [
            doc for doc in processed_data 
        ]
        
        get_kiwi_instance()
        
        kiwi_bm25 = BM25Retriever.from_documents(
            processed_data, 
            preprocess_func=kiwi_tokenize
        )
        
        kiwi_bm25.k = 3
        
        vectorstore = FAISS.from_documents(
            processed_data,
            embedding_model,
        )
        
        faiss_retriever = vectorstore.as_retriever(
        )

        retriever = EnsembleRetriever(
            retrievers=[kiwi_bm25, faiss_retriever],
            weights=[0.7, 0.3],  # BM25ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
            search_type="mmr"
        )

        return retriever, len(processed_data), processed_data
    except Exception as e:
        st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None, None

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ìºì‹œ í•¨ìˆ˜
@st.cache_resource
def load_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    embedding_model = HuggingFaceEmbeddings(
        model_name='jhgan/ko-sroberta-multitask',
        model_kwargs={'device': 'cuda'},
        encode_kwargs={'normalize_embeddings': True},
    )
    return embedding_model


# LLM ëª¨ë¸ ë¡œë“œ ìºì‹œ í•¨ìˆ˜ 
@st.cache_resource
def load_llm_model():
    """LLM ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    model_name = "MLP-KTLim/llama-3-Korean-Bllossom-8B"
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    llm_pipeline = pipeline(
        "text-generation",
        model=model_name,
        tokenizer=tokenizer,
        model_kwargs={"torch_dtype": torch.bfloat16},
        device_map="auto",
        max_new_tokens=512,
        temperature=1.0,  # ì˜ë¯¸ ì—†ìŒ, ì œê±° ê°€ëŠ¥
        do_sample=False,  # í™•ë¥ ì  ì¶œë ¥ ì œê±°
        early_stopping=True,
        pad_token_id=tokenizer.eos_token_id,
        num_beams=4,  # ë¹” ì„œì¹˜ë¡œ ì •í™•ë„ í–¥ìƒ
    )

    llm = HuggingFacePipeline(pipeline=llm_pipeline)
    return llm

# ê³µí†µ ë¬¸ì„œ ì²˜ë¦¬ í•¨ìˆ˜
def _process_query(question, chat_name):    
    """ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  í”„ë¡¬í”„íŠ¸ì™€ ì¶œì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if st.session_state.get("retriever") is None:
        return None, "PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", [], []
    
    # clean_text í•¨ìˆ˜ ì •ì˜
    def clean_text(text):
        text = re.sub(r'<[^>]+>', '', text)
        return re.sub(r'\s+', ' ', text.strip())

    # EnsembleRetriever ì‚¬ìš© (ì„¤ì •ëœ k ê°’ì— ë”°ë¼ ê²€ìƒ‰)
    try:
        docs = st.session_state.retriever.invoke(question, k=3)
    except Exception as e:
        return None, f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", [], []

    if not docs:
        return None, "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë‚˜ í‘œí˜„ìœ¼ë¡œ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.", [], []

    # ë¬¸ì„œ í’ˆì§ˆ í•„í„°ë§
    quality_docs = []
    for doc in docs:
        cleaned_content = clean_text(doc.page_content)
        if len(cleaned_content.strip()) > 100:
            quality_docs.append(doc)

    if not quality_docs:
        return None, "ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆì´ ë‚®ì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.", [], []

    # ì°¸ê³ ìë£Œì™€ ì¶œì²˜ ì •ë¦¬
    context_parts = []
    sources = []
    search_results = []  # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ë³€ìˆ˜
    
    for i, doc in enumerate(quality_docs[:3]):
        clean_content = clean_text(doc.page_content)
        context_parts.append(f"[ì°¸ê³ ìë£Œ {i+1}]\n{clean_content[:500]}")
        
        # í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
        page_num = doc.metadata.get('page', 'ì•Œ ìˆ˜ ì—†ìŒ')
        source_file = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
        
        # ì¶œì²˜ ì •ë³´ ìƒì„±
        if page_num != 'ì•Œ ìˆ˜ ì—†ìŒ':
            source_info = f"ğŸ“„ í˜ì´ì§€ {page_num}"
            if source_file != 'ì•Œ ìˆ˜ ì—†ìŒ':
                source_info += f" ({source_file})"
        else:
            source_info = f"ğŸ“„ {source_file}"
        
        sources.append(source_info)
        
        # ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ (ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìš©ë„)
        search_results.append({
            'content': clean_content[:500] + "..." if len(clean_content) > 500 else clean_content,
            'page': page_num,
            'source': source_file
        })

    context = "\n\n".join(context_parts)

    # ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    conversation_history = format_conversation_history(chat_name)
    history = get_conversation_history(chat_name)
    
    # ì²« ë²ˆì§¸ ì§ˆë¬¸ì¸ì§€ í™•ì¸
    is_first_question = len(history) == 0
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„± (ì²« ë²ˆì§¸ ì§ˆë¬¸ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ìƒì„±)
    if is_first_question:
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ - êµ¬ì¡°í™”ëœ ì •ì±… ë²ˆí˜¸ë³„ ì¶”ì²œ
        prompt = f"""í•œêµ­ ë³µì§€ì •ì±… ì „ë¬¸ê°€ë¡œì„œ, ì•„ë˜ ì°¸ê³ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì•Œê¸° ì‰½ê³  ì •í™•í•˜ê²Œ ë³µì§€ ì •ì±…ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.

ë§Œì•½ ë¬¸ì„œì— ë‹µì´ ì—†ê±°ë‚˜ ë¶ˆì™„ì „í•˜ë‹¤ë©´, ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€í•´ ì£¼ì„¸ìš”:
1. í˜„ì¬ ì œê³µ ê°€ëŠ¥í•œ ì •ë³´ë¥¼ ë¨¼ì € ì•Œë ¤ì£¼ì„¸ìš”.
2. ë¶€ì¡±í•œ ì •ë³´ì— ëŒ€í•´ "ì¶”ê°€ë¡œ ë‹¤ìŒ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤:" í˜•íƒœë¡œ ëª…ì‹œí•´ ì£¼ì„¸ìš”.
3. ì‚¬ìš©ìê°€ ì–´ë–¤ ì •ë³´ë¥¼ ë” ì œê³µí•˜ë©´ ë„ì›€ì´ ë ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.

[ì‚¬ìš©ì ì§ˆë¬¸]:
{question}

[ì°¸ê³ ìë£Œ]:
{context}

[ë‹µë³€ ì¤‘ìš” ì§€ì¹¨]:
1. ìµœëŒ€ 3ê°œ ì •ì±…ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.  
2. ê° ì •ì±…ë§ˆë‹¤ ì•„ë˜ 6ê°œ í•­ëª©ì„ ëª¨ë‘ ì‘ì„±í•´ ì£¼ì„¸ìš”.  
3. ë‹µë³€ ë§ˆì§€ë§‰ì€ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ ì£¼ì„¸ìš”.
4. ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°, ì–´ë–¤ ê°œì¸ì •ë³´ë‚˜ ìƒí™© ì •ë³´ê°€ ì¶”ê°€ë¡œ í•„ìš”í•œì§€ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.

[í•„ìˆ˜ í˜•ì‹]:
### ì •ì±… [ë²ˆí˜¸]: [ì •ì±…ëª…]
- ìš”ì•½: [ìš”ì•½ ë‚´ìš©]
- ëŒ€ìƒ: [ëŒ€ìƒ ë‚´ìš©]
- ì§€ì›: [ì§€ì› ë‚´ìš©]
- ë°©ë²•: [ë°©ë²• ë‚´ìš©]
- ì£¼ì˜: [ì£¼ì˜ ë‚´ìš©]
- ë¬¸ì˜: [ë¬¸ì˜ ë‚´ìš©]

[ì •ë³´ ë¶€ì¡± ì‹œ ì¶”ê°€ ì•ˆë‚´]:
ë” ì •í™•í•œ ì •ì±… ì¶”ì²œì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤:
- ë‚˜ì´, ì„±ë³„, ê±°ì£¼ì§€ì—­
- ì†Œë“ ìˆ˜ì¤€, ê°€êµ¬ í˜•íƒœ
- ê²°í˜¼ ì—¬ë¶€, ìë…€ ìˆ˜
- ì·¨ì—… ìƒíƒœ, íŠ¹ë³„í•œ ìƒí™©(ì„ì‹ , ì¥ì•  ë“±)

ë‹µë³€:"""
    else:
        # í›„ì† ì§ˆë¬¸ - ìœ ë™ì ì¸ ë‹µë³€
        prompt = f"""í•œêµ­ ë³µì§€ì •ì±… ì „ë¬¸ê°€ë¡œì„œ, ì•„ë˜ ì°¸ê³ ìë£Œì™€ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”.

{conversation_history}

[í˜„ì¬ ì‚¬ìš©ì ì§ˆë¬¸]:
{question}

[ì°¸ê³ ìë£Œ]:
{context}

[ë‹µë³€ ì¤‘ìš” ì§€ì¹¨]:
1. ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ì°¸ê³ í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”.
2. ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ìƒí™©ì— ë§ê²Œ ìœ ë™ì ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.
3. ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°, êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.
4. ì •ì±… ì¶”ì²œ ì‹œì—ëŠ” ì‚¬ìš©ìì˜ ìƒí™©ì— ê°€ì¥ ì í•©í•œ ì •ì±…ì„ ìš°ì„ ì ìœ¼ë¡œ ì†Œê°œí•´ ì£¼ì„¸ìš”.
5. ë‹µë³€ì€ ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

ë‹µë³€:"""

    return prompt, None, sources, search_results

# ë‹µë³€ì—ì„œ í”„ë¡¬í”„íŠ¸ ì œê±° í•¨ìˆ˜
def _extract_answer_only(response):
    """LLM ì‘ë‹µì—ì„œ ë‹µë³€ ë¶€ë¶„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not response:
        return response
    
    # "ë‹µë³€" í‚¤ì›Œë“œ ì´í›„ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
    answer_markers = ["ë‹µë³€:", "ë‹µë³€", "Answer:", "Answer"]
    
    for marker in answer_markers:
        if marker in response:
            parts = response.split(marker, 1)
            if len(parts) > 1:
                return parts[1].strip()
    
    # ë‹µë³€ ë§ˆì»¤ê°€ ì—†ìœ¼ë©´ ### ì •ì±…ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ë¶€í„° ì¶”ì¶œ
    lines = response.split('\n')
    answer_lines = []
    start_found = False
    
    for line in lines:
        if line.strip().startswith('### ì •ì±…: '):
            start_found = True
        if start_found:
            answer_lines.append(line)
    
    if answer_lines:
        return '\n'.join(answer_lines)
    
    return response

# ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ë‹µë³€ ìƒì„± í•¨ìˆ˜
def generate_answer_streaming(question, chat_name):
    """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)."""
    try:
        result = _process_query(question, chat_name)
        
        if len(result) == 4:
            prompt, error_msg, sources, search_results = result
        else:
            # ì´ì „ í˜•ì‹ ì§€ì› (3ê°œ ë°˜í™˜ê°’)
            prompt, error_msg, sources = result
            search_results = []
        
        if error_msg:
            yield error_msg, [], []
            return
        
        # LLM ì‘ë‹µ ìƒì„±
        try:
            response = st.session_state.llm.predict(prompt)
            if response is None:
                yield "ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", [], []
                return
            
            # ë‹µë³€ì—ì„œ í”„ë¡¬í”„íŠ¸ ì œê±°
            clean_response = _extract_answer_only(response)
            clean_response = remove_emojis_and_enclosed_chars(clean_response)

            save_conversation_to_cache(chat_name, question, clean_response)

            # ìŠ¤íŠ¸ë¦¬ë° ì‹œë®¬ë ˆì´ì…˜
            words = clean_response.split(' ')

            for i in range(0, len(words), 5):  # 5ë‹¨ì–´ì”© ì¶œë ¥
                yield " ".join(words[:i+5]), sources, search_results
                time.sleep(0.1)
                
        except Exception as e:
            yield f"LLM ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [], []

    except Exception as e:
        yield f"ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [], []

# í”¼ë“œë°± ì²˜ë¦¬ í•¨ìˆ˜
def on_feedback(feedback, chat_history_id: str = "", history_index: int = -1):
    """í”¼ë“œë°±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    reason = feedback.get("text", "")
    score = feedback.get("score", 0)
    
    # í”¼ë“œë°± ì €ì¥ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥)
    if "feedback_history" not in st.session_state:
        st.session_state.feedback_history = []
    
    st.session_state.feedback_history.append({
        "chat_history_id": chat_history_id,
        "history_index": history_index,
        "score": score,
        "reason": reason,
        "timestamp": time.time()
    })
    
    st.session_state["need_rerun"] = True

# ì¶”ê°€ ë¬¸ì„œ ë¡œë“œ í•¨ìˆ˜
def load_additional_documents(uploaded_files):
    """ì¶”ê°€ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    pdf_dir = "./pdf/welfare"
    
    with st.spinner("ì¶”ê°€ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            # ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            additional_files = []
            for uploaded_file in uploaded_files:
                with open(uploaded_file.name, "wb") as f:
                    f.write(uploaded_file.getvalue())
                additional_files.append(uploaded_file.name)
            
            # ê¸°ë³¸ ë¬¸ì„œì™€ ì¶”ê°€ ë¬¸ì„œ í•©ì¹˜ê¸°
            all_files = []
            
            # ê¸°ë³¸ ë¬¸ì„œ ì¶”ê°€
            if os.path.exists(pdf_dir):
                pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]
                all_files.extend(pdf_files)
            
            # ì¶”ê°€ ë¬¸ì„œ ì¶”ê°€
            all_files.extend(additional_files)
            
            st.info(f"ê¸°ë³¸ ë¬¸ì„œ í¬í•¨ ì´ {len(all_files)}ê°œ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...")

            # EnsembleRetriever ë°©ì‹ìœ¼ë¡œ ë¬¸ì„œ ë¡œë“œ ë° ì²˜ë¦¬
            result = load_and_process_documents(all_files, st.session_state.embedding_model)
            
            if result[0] is not None:  # retrieverê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                retriever, total_chunks, processed_docs = result
                st.session_state.retriever = retriever
                st.session_state.processed_docs = processed_docs
                
                st.success(f"âœ… ì¶”ê°€ ë¬¸ì„œ í¬í•¨ ì´ {len(all_files)}ê°œ ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.session_state.documents_loaded = True
                return True
            else:
                st.error("ì¶”ê°€ ë¬¸ì„œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            st.error(f"ì¶”ê°€ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False

# ê¸°ë³¸ ë¬¸ì„œ ìë™ ë¡œë“œ í•¨ìˆ˜ (EnsembleRetriever ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •)
def load_default_documents():
    """í˜ì´ì§€ ì‹œì‘ ì‹œ ê¸°ë³¸ ë³µì§€ ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
    if st.session_state.get("default_documents_loaded", False):
        return
    
    pdf_dir = "./pdf/welfare"
    
    if os.path.exists(pdf_dir):
        pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]
        
        if pdf_files:
            try:
                with st.spinner("ê¸°ë³¸ ë³µì§€ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
                    if "embedding_model" not in st.session_state:
                        st.session_state.embedding_model = load_embedding_model()
                    
                    # EnsembleRetriever ë°©ì‹ìœ¼ë¡œ ë¬¸ì„œ ë¡œë“œ ë° ì²˜ë¦¬
                    result = load_and_process_documents(pdf_files, st.session_state.embedding_model)
                    if result[0] is not None:  # retrieverê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        retriever, total_chunks, processed_docs = result
                        st.session_state.retriever = retriever
                        st.session_state.processed_docs = processed_docs
                        
                        # LLM ëª¨ë¸ ë¡œë“œ
                        if "llm" not in st.session_state:
                            st.session_state.llm = load_llm_model()
                        
                        st.session_state.default_documents_loaded = True
                        st.session_state.documents_loaded = True
                        st.success(f"âœ… ê¸°ë³¸ ë³µì§€ ë¬¸ì„œ {total_chunks}ê°œ ì²­í¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.success(f"âœ… ê¸°ë³¸ ë³µì§€ ë¬¸ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
            except Exception as e:
                st.error(f"ê¸°ë³¸ ë¬¸ì„œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ë©”ì¸ ì•±
def main():
    st.set_page_config(
        page_title="ë³µì§€PT",
        page_icon="ğŸ›ï¸",
        layout="wide"
    )
    
    # ChatBox ì´ˆê¸°í™”
    st.session_state.chat_box = ChatBox(
        use_rich_markdown=True,  # Trueë¡œ ë³€ê²½
        user_theme="green",
        assistant_theme="blue",
    )
    st.session_state.chat_box.use_chat_name("welfare_chat")
    
    # í˜„ì¬ ì±„íŒ… ì´ˆê¸°í™”
    if "current_chat" not in st.session_state:
        st.session_state.current_chat = "welfare_chat"
    
    # ë§ˆì´í¬ ìƒíƒœ ì´ˆê¸°í™”
    if "mic_active" not in st.session_state:
        st.session_state.mic_active = False
    
    chat_box = st.session_state.chat_box
    
    # ê¸°ë³¸ ë¬¸ì„œ ìë™ ë¡œë“œ
    load_default_documents()
    
    # ì‚¬ì´ë“œë°” êµ¬ì„±
    with st.sidebar:        
        # ìƒˆ ì±„íŒ… ì¶”ê°€ ë²„íŠ¼
        # "ìƒˆ ì±„íŒ…" ë²„íŠ¼ì„ íšŒìƒ‰(secondary) ìŠ¤íƒ€ì¼ë¡œ ë³€ê²½
        if st.button("ğŸ“ ìƒˆ ì±„íŒ…", type="secondary", use_container_width=True):
            start_new_chat()
        
        st.divider()
        
        # ì±„íŒ… í‘œì‹œ
        st.subheader("ì±„íŒ…")
        chat_list = get_chat_list()
        
        for i, chat in enumerate(chat_list):
            display_text = f"{chat[:20]}..." if len(chat) > 20 else chat
            
            # í˜„ì¬ ì±„íŒ… í‘œì‹œ
            if chat == st.session_state.current_chat:
                # í˜„ì¬ ì±„íŒ…ì€ ë…¹ìƒ‰ ë°°ê²½, ì‚­ì œ ë²„íŠ¼ í¬í•¨
                col1, col2 = st.columns([5, 1])
                
                with col1:
                    # ì§„í•œ íšŒìƒ‰ ë°°ê²½, ì‚¬ì´ì¦ˆ ë™ì¼í•˜ê²Œ í˜„ì¬ ì±„íŒ… í‘œì‹œ
                    st.markdown(
                        f'<div style="background-color: #444444; padding: 8px; border-radius: 8px; font-weight: bold; color: #FFFFFF; width: 100%;">'
                        f'{display_text}'
                        f'</div>',
                        unsafe_allow_html=True
                    )
                
                with col2:
                    if len(chat_list) > 1:  # ìµœì†Œ í•˜ë‚˜ì˜ ì±„íŒ…ì€ ìœ ì§€
                        if st.button("ğŸ—‘ï¸", key=f"delete_current_{i}", help="í˜„ì¬ ì±„íŒ… ì‚­ì œ", 
                                    use_container_width=False):
                            delete_chat(chat)
                            st.rerun()
            else:
                # ë‹¤ë¥¸ ì±„íŒ…ì€ íšŒìƒ‰ ë°°ê²½
                col1, col2 = st.columns([5, 1])
                
                with col1:
                    # íšŒìƒ‰ ë°°ê²½ ì±„íŒ… ì˜ì—­
                    if st.button(
                        f"{display_text}",
                        key=f"chat_{i}",
                        use_container_width=True,
                        help="ì±„íŒ… ì„ íƒ"
                    ):
                        st.session_state.current_chat = chat
                        st.session_state.chat_box.use_chat_name(chat)
                        st.rerun()

                
                with col2:
                    if len(chat_list) > 1:  # ìµœì†Œ í•˜ë‚˜ì˜ ì±„íŒ…ì€ ìœ ì§€
                        if st.button("ğŸ—‘ï¸", key=f"delete_other_{i}", help="ì±„íŒ… ì‚­ì œ", 
                                    use_container_width=False):
                            delete_chat(chat)
                            st.rerun()
        
        st.divider()
        
        # ì„¤ì • ì˜µì…˜
        show_history = st.checkbox('ì„¸ì…˜ ìƒíƒœ ë³´ê¸°', key="show_history")
        
        chat_box.context_from_session(exclude=["current_chat"])
        
        st.divider()
        
        # ë¬¸ì„œ ìƒíƒœ í‘œì‹œ
        st.subheader("ë¬¸ì„œ ìƒíƒœ")
        
        pdf_dir = "./pdf/welfare"
        
        # ê¸°ë³¸ ë¬¸ì„œ ìƒíƒœ í‘œì‹œ
        if st.session_state.get("default_documents_loaded", False):
            if os.path.exists(pdf_dir):
                default_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]
                st.success(f"âœ… ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œ {len(default_files)}ê°œ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                with st.expander("ê¸°ë³¸ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
                    for file in default_files:
                        st.write(f"ğŸ“„ {file}")
            else:
                st.warning("âš ï¸ ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if os.path.exists(pdf_dir) and len([f for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]) > 0:
                st.info("â³ ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
            else:
                st.warning("âš ï¸ pdf/welfare í´ë”ì— ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¶”ê°€ ë¬¸ì„œ ì—…ë¡œë“œ ì„¹ì…˜
        st.subheader("ì¶”ê°€ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        uploaded_files = st.file_uploader(
            "ì¶”ê°€ ë³µì§€ ì •ì±… PDF íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒì‚¬í•­)",
            type=["pdf"],
            accept_multiple_files=True,
            help="ê¸°ë³¸ ë¬¸ì„œì— ì¶”ê°€ë¡œ ë” ë§ì€ ì •ì±… ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        # ì¶”ê°€ ë¬¸ì„œ ë¡œë“œ ë²„íŠ¼
        if st.button("ì¶”ê°€ ë¬¸ì„œ ë¡œë“œ", type="secondary"):
            if uploaded_files:
                success = load_additional_documents(uploaded_files)
                if success:
                    st.rerun()
            else:
                st.warning("ì—…ë¡œë“œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        st.divider()
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    # ë©‹ì§„ ì²« í™”ë©´ ë¬¸êµ¬ì™€ í°íŠ¸ í¬ê¸° ì¡°ì •
    st.markdown(
        """
        <h1 style='text-align: center; font-size: 3.2em;'>ë³µì§€PTì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!</h1>
        <p style='text-align: center; font-size: 1.5em; color: #555;'>
            ë‹¹ì‹ ì˜ ìƒí™©ì— ê¼­ ë§ëŠ” ë³µì§€ ì •ì±…ì„ <b>AI</b>ê°€ ì‰½ê³  ë¹ ë¥´ê²Œ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.<br>
            ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ì…ë ¥í•´ë³´ì„¸ìš”!
        </p>
        """,
        unsafe_allow_html=True
    )
    
    # ì‚¬ìš© íŒ í‘œì‹œ
    if not st.session_state.get("chat_started", False):
        st.info("""
        ğŸ’¡ **ì‚¬ìš© íŒ**
        - êµ¬ì²´ì ì¸ ìƒí™©ì„ ì„¤ëª…í•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        - ì˜ˆì‹œ: "30ëŒ€ ì‹ í˜¼ë¶€ë¶€ë¥¼ ìœ„í•œ ì£¼ê±° ì§€ì› ì •ì±…ì„ ì•Œë ¤ì£¼ì„¸ìš”"
        - ë‚˜ì´, ì†Œë“, ê°€êµ¬ í˜•íƒœ ë“±ì˜ ì •ë³´ë¥¼ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”
        - ì¶”ê°€ì ì¸ ë¬¸ì„œ(PDF)ë¥¼ ì—…ë¡œë“œí•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì„ íƒì‚¬í•­)
        - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤
        - ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìƒˆ ì±„íŒ…ì„ ìƒì„±í•˜ê±°ë‚˜ ê¸°ì¡´ ì±„íŒ…ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        """)
    
    # ì±„íŒ…ì´ ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if len(st.session_state.chat_box.history) > 0:
        st.session_state.chat_started = True
    
    # í˜„ì¬ ì±„íŒ…ìœ¼ë¡œ ì„¤ì •
    chat_box.use_chat_name(st.session_state.current_chat)
    
    # ì±„íŒ… ë°•ìŠ¤ ì´ˆê¸°í™” ë° ì¶œë ¥
    chat_box.init_session()
    chat_box.output_messages()
    
    # í”¼ë“œë°± ì„¤ì •
    feedback_kwargs = {
        "feedback_type": "thumbs",
        "optional_text_label": "í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”",
    }
    
    # ì±„íŒ… ì…ë ¥ì°½ í•˜ë‹¨ ê³ ì •ì„ ìœ„í•œ CSS
    st.markdown(
        """
        <style>
        /* í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¡¤ ì‹œ ì±„íŒ… ì…ë ¥ì°½ ê³ ì • */
        .main .block-container {
            padding-bottom: 120px !important;
        }
        
        /* ì±„íŒ… ì…ë ¥ì°½ ê³ ì • ìŠ¤íƒ€ì¼ */
        .fixed-bottom {
            position: fixed !important;
            bottom: 0 !important;
            left: 0 !important;
            right: 0 !important;
            background: rgba(255, 255, 255, 0.98) !important;
            backdrop-filter: blur(15px) !important;
            padding: 20px !important;
            border-top: 2px solid #e6e6e6 !important;
            box-shadow: 0 -4px 20px rgba(0,0,0,0.15) !important;
            z-index: 9999 !important;
        }
        
        /* ì‚¬ì´ë“œë°”ê°€ ìˆëŠ” ê²½ìš° ì™¼ìª½ ì—¬ë°± ì¡°ì • */
        .fixed-bottom {
            left: 21rem !important;
        }
        
        /* ë°ìŠ¤í¬í†±ì—ì„œ ì‚¬ì´ë“œë°” ë„ˆë¹„ ì¡°ì • */
        @media (max-width: 768px) {
            .fixed-bottom {
                left: 0 !important;
                right: 0 !important;
            }
        }
        
        /* ë§ˆì´í¬ ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        .mic-button {
            display: flex !important;
            align-items: center !important;
            height: 100% !important;
        }
        
        /* ì±„íŒ… ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ ê°œì„  */
        .stChatInput > div {
            margin-bottom: 0 !important;
        }
        
        /* ì „ì²´ ì±„íŒ… ì…ë ¥ì°½ ì»¨í…Œì´ë„ˆ */
        .fixed-bottom [data-testid="column"] {
            gap: 10px !important;
        }
        
        /* ì±„íŒ… ì…ë ¥ì°½ ìì²´ ìŠ¤íƒ€ì¼ */
        .fixed-bottom .stChatInput {
            margin-bottom: 0 !important;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
    
    # í•˜ë‹¨ ê³ ì • ì…ë ¥ ì˜ì—­
    st.markdown('<div class="fixed-bottom">', unsafe_allow_html=True)
    
    # ì±„íŒ… ì…ë ¥ UI - ë§ˆì´í¬ ë²„íŠ¼ ì¶”ê°€ (í•˜ë‹¨ ê³ ì •)
    col1, col2 = st.columns([10, 1])
    
    with col1:
        # ì²« ë²ˆì§¸ ì§ˆë¬¸ì¸ì§€ í™•ì¸í•˜ì—¬ í”Œë ˆì´ìŠ¤í™€ë” ë©”ì‹œì§€ ë³€ê²½
        current_chat = st.session_state.current_chat
        history = get_conversation_history(current_chat)
        is_first_question = len(history) == 0 and len(st.session_state.chat_box.history) == 0
        
        if is_first_question:
            placeholder_text = "ë³µì§€ ì •ì±…ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”. (ì˜ˆ: 30ëŒ€ ì‹ í˜¼ë¶€ë¶€ ì£¼ê±° ì§€ì› ì •ì±…)"
        else:
            placeholder_text = "ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        query = st.chat_input(placeholder_text)
    
    with col2:
        st.markdown('<div class="mic-button">', unsafe_allow_html=True)
        # ë§ˆì´í¬ ë²„íŠ¼ (ê¸°ëŠ¥ ì—†ìŒ, ì‹œê°ì  íš¨ê³¼ë§Œ)
        if st.button("ğŸ¤", key="mic_button", type="secondary" if not st.session_state.mic_active else "primary"):
            st.session_state.mic_active = not st.session_state.mic_active
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('</div>', unsafe_allow_html=True)
        
    # ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
    if query:
        # ê¸°ë³¸ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if not st.session_state.get("default_documents_loaded", False):
            st.error("â³ ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!")
            return
        
        # í˜„ì¬ ì±„íŒ… ì´ë¦„ ì„¤ì •
        current_chat = st.session_state.current_chat
        
        # í˜„ì¬ ì±„íŒ…ì´ ë¹„ì–´ìˆê³  ê¸°ë³¸ ì´ë¦„ì¸ ê²½ìš° ìë™ ì´ë¦„ ìƒì„±
        if (current_chat == "welfare_chat" and 
            len(get_conversation_history(current_chat)) == 0 and
            len(st.session_state.chat_box.history) == 0):
            
            # ì§ˆë¬¸ ê¸°ë°˜ìœ¼ë¡œ ì±„íŒ… ì´ë¦„ ìƒì„±
            chat_name_preview = query[:20] + "..." if len(query) > 20 else query
            chat_name_preview = re.sub(r'[^\w\sê°€-í£]', '', chat_name_preview)
            
            # ì±„íŒ… ë¦¬ìŠ¤íŠ¸ì—ì„œ ê¸°ë³¸ ì´ë¦„ êµì²´
            if "welfare_chat" in st.session_state.chat_list:
                index = st.session_state.chat_list.index("welfare_chat")
                st.session_state.chat_list[index] = chat_name_preview
                st.session_state.current_chat = chat_name_preview
                current_chat = chat_name_preview
        
        chat_box.use_chat_name(current_chat)
        chat_box.user_say(query)
        
        try:
            elements = chat_box.ai_say([
                "ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "",
            ])
            
            generator = generate_answer_streaming(question=query, chat_name=current_chat)
            
            text = ""
            sources = []
            search_results = []
            try:
                for response, doc_sources, doc_search_results in generator:
                    text = response
                    sources = doc_sources
                    search_results = doc_search_results
                    chat_box.update_msg(text, element_index=0, streaming=True)
            except Exception as e:
                text = f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                sources = []
                search_results = []
            
            chat_box.update_msg(text, element_index=0, streaming=False, state="complete")
            
            # ê²€ìƒ‰ ê²°ê³¼ì™€ ì°¸ê³ ìë£Œ í‘œì‹œ
            reference_text = ""
            if search_results:
                reference_text += "ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´:\n\n"
                for i, result in enumerate(search_results, 1):
                    reference_text += f"{i}. {os.path.basename(result['source'])} (í˜ì´ì§€ {result['page']})\n"
                    reference_text += f"{result['content']}\n\n"
                reference_text += "---\n\n"
            
            if sources:
                reference_text += "ì°¸ê³ ìë£Œ:\n" + "\n".join(sources)
            else:
                reference_text += "ì°¸ê³ ìë£Œ: ì—†ìŒ"
            
            chat_box.update_msg(reference_text, element_index=1, streaming=False, state="complete")
            
            # í”¼ë“œë°± í‘œì‹œ
            chat_history_id = f"chat_{len(chat_box.history)}"
            chat_box.show_feedback(
                **feedback_kwargs,
                key=chat_history_id,
                on_submit=on_feedback,
                kwargs={"chat_history_id": chat_history_id, "history_index": len(chat_box.history) - 1}
            )
        except Exception as e:
            chat_box.ai_say([
                f"ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì˜¤ë¥˜: {str(e)}",
                "ğŸ“„ ì°¸ê³ ìë£Œ: ì—†ìŒ",
            ])
    
    # ì„¸ì…˜ ìƒíƒœ ë³´ê¸°
    if show_history:
        st.subheader("ì„¸ì…˜ ìƒíƒœ")
        st.write(f"í˜„ì¬ ì±„íŒ…: {st.session_state.current_chat}")
        st.write(f"ë§ˆì´í¬ ìƒíƒœ: {'í™œì„±í™”' if st.session_state.mic_active else 'ë¹„í™œì„±í™”'}")
        st.write(f"ì±„íŒ… ëª©ë¡: {get_chat_list()}")
        
        # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
        st.write("ëŒ€í™” ê¸°ë¡:")
        history = get_conversation_history(st.session_state.current_chat)
        for i, conv in enumerate(history, 1):
            st.write(f"{i}. Q: {conv['question'][:50]}...")
            st.write(f"   A: {conv['answer'][:100]}...")
        
        with st.expander("ì „ì²´ ì„¸ì…˜ ìƒíƒœ ë³´ê¸°"):
            st.write(st.session_state)

if __name__ == "__main__":
    main() 