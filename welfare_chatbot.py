# ë³µì§€ ì •ì±… LLM ì±—ë´‡ - streamlit_chatbox ê¸°ë°˜

import streamlit as st
from streamlit_chatbox import *
import time
import simplejson as json
import re
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.llms import HuggingFacePipeline
from transformers import AutoTokenizer, pipeline
import torch
from langchain.schema import Document
from typing import List
import unicodedata

# ì´ëª¨ì§€ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±° í•¨ìˆ˜
def remove_emojis_and_enclosed_chars(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì´ëª¨ì§€ì™€ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
    return ''.join(
        ch for ch in text
        if not (
            unicodedata.category(ch).startswith('So')
            or (0x1F000 <= ord(ch) <= 0x1FFFF)
            or (0x2460 <= ord(ch) <= 0x24FF)
        )
    )

# ë¬¸ì„œ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_document(text):
    """ë¬¸ì„œì—ì„œ ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´, íƒœê·¸, ì´ëª¨ì§€ ë“±ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
    text = remove_emojis_and_enclosed_chars(text)
    text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
    text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'(\*\*|\*|_)', '', text)
    text = re.sub(r'^[-\*\+]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'\n+', '\n', text).strip()
    return text

# ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def process_pages(pages: List[Document]) -> List[Document]:
    """ê° ë¬¸ì„œë¥¼ ì „ì²˜ë¦¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return [Document(page_content=preprocess_document(page.page_content), metadata=page.metadata) for page in pages]

# ë¬¸ì„œ ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜
def load_and_process_documents(file_paths: List[str]):
    """ì—¬ëŸ¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    all_documents = []
    
    for file_path in file_paths:
        try:
            loader = PyMuPDFLoader(file_path)
            documents = loader.load()
            all_documents.extend(documents)
        except Exception as e:
            st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({file_path}): {str(e)}")
            continue
    
    if not all_documents:
        return []
    
    processed_data = process_pages(all_documents)
    
    # ë¬¸ì„œë¥¼ í…ìŠ¤íŠ¸ ì²­í¬ë¡œ ë¶„í• 
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
        separators=["\n\n", "\n", "ã€‚", ".", "!", "?", ";", ":", " "]
    )
    texts = text_splitter.split_documents(processed_data)
    return texts

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ìºì‹œ í•¨ìˆ˜
@st.cache_resource
def load_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    embedding_model = HuggingFaceEmbeddings(
        model_name='jhgan/ko-sroberta-nli',
        model_kwargs={'device': 'cuda'},
        encode_kwargs={'normalize_embeddings': True},
    )
    return embedding_model

# ë²¡í„°ìŠ¤í† ì–´ ìƒì„± í•¨ìˆ˜
def create_vectorstore(texts, embedding_model):
    """í…ìŠ¤íŠ¸ ì²­í¬ì™€ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not texts:
        return None
    db = Chroma.from_documents(texts, embedding=embedding_model)
    return db

# LLM ëª¨ë¸ ë¡œë“œ ìºì‹œ í•¨ìˆ˜
@st.cache_resource
def load_llm_model():
    """LLM ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    model_name = "MLP-KTLim/llama-3-Korean-Bllossom-8B"
    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
    llm_pipeline = pipeline(
        "text-generation",
        model=model_name,
        model_kwargs={"torch_dtype": torch.bfloat16},
        device_map="auto",
        max_new_tokens=512,
        early_stopping=True,
        temperature=0.5,
        do_sample=True,
        pad_token_id=tokenizer.eos_token_id,
        repetition_penalty=1.1,
    )
    llm = HuggingFacePipeline(pipeline=llm_pipeline)
    return llm

# ê³µí†µ ë¬¸ì„œ ì²˜ë¦¬ í•¨ìˆ˜
def _process_query(question, age=None, gender=None, location=None, income=None, family_size=None, marriage=None, children=None, children_ages=None, basic_living=None, employment_status=None, pregnancy_status=None, nationality=None, disability=None, military_service=None):    
    """ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  í”„ë¡¬í”„íŠ¸ì™€ ì¶œì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if st.session_state.get("db") is None:
        return None, "PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", []
    
    # clean_text í•¨ìˆ˜ ì •ì˜
    def clean_text(text):
        text = re.sub(r'<[^>]+>', '', text)
        return re.sub(r'\s+', ' ', text.strip())

    # ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    retriever = st.session_state.db.as_retriever(search_type="similarity", k=3)
    docs = retriever.get_relevant_documents(question)

    if not docs:
        return None, "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

    # ë¬¸ì„œ í’ˆì§ˆ í•„í„°ë§
    quality_docs = []
    for doc in docs:
        cleaned_content = clean_text(doc.page_content)
        if len(cleaned_content.strip()) > 100:
            quality_docs.append(doc)

    if not quality_docs:
        return None, "ê²€ìƒ‰ëœ ë¬¸ì„œì˜ í’ˆì§ˆì´ ë‚®ì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

    # ì°¸ê³ ìë£Œì™€ ì¶œì²˜ ì •ë¦¬
    context_parts = []
    sources = []
    search_results = []  # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° ìœ„í•œ ë³€ìˆ˜
    
    for i, doc in enumerate(quality_docs[:3]):
        clean_content = clean_text(doc.page_content)
        context_parts.append(f"[ì°¸ê³ ìë£Œ {i+1}]\n{clean_content[:1024]}")
        
        # í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
        page_num = doc.metadata.get('page', 'ì•Œ ìˆ˜ ì—†ìŒ')
        source_file = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
        
        # ì¶œì²˜ ì •ë³´ ìƒì„±
        if page_num != 'ì•Œ ìˆ˜ ì—†ìŒ':
            source_info = f"ğŸ“„ í˜ì´ì§€ {page_num}"
            if source_file != 'ì•Œ ìˆ˜ ì—†ìŒ':
                source_info += f" ({source_file})"
        else:
            source_info = f"ğŸ“„ {source_file}"
        
        sources.append(source_info)
        
        # ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ (ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìš©ë„)
        search_results.append({
            'content': clean_content[:500] + "..." if len(clean_content) > 500 else clean_content,
            'page': page_num,
            'source': source_file
        })

    context = "\n\n".join(context_parts)

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    user_info = []
    if age is not None:
        user_info.append(f"ë‚˜ì´: {age}")
    if gender is not None:
        user_info.append(f"ì„±ë³„: {gender}")
    if location is not None:
        user_info.append(f"ê±°ì£¼ì§€: {location}")
    if income is not None:
        user_info.append(f"ì†Œë“: ì¤‘ìœ„ {income}%")
    if family_size is not None:
        user_info.append(f"ê°€êµ¬ í˜•íƒœ: {family_size}")
    if marriage is not None:
        user_info.append(f"ê²°í˜¼ ìœ ë¬´: {marriage}")
    if children is not None:
        user_info.append(f"ìë…€ ìˆ˜: {children}ëª…")        
    if children_ages is not None:
        # ìë…€ê°€ ì—¬ëŸ¬ ëª…ì¼ ê²½ìš°, ê° ìë…€ì˜ ë‚˜ì´ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤.
        if isinstance(children_ages, list) and len(children_ages) > 1:
            ages_str = ", ".join(str(age) for age in children_ages)
            user_info.append(f"ìë…€ ë‚˜ì´: {ages_str}")
        else:
            user_info.append(f"ìë…€ ë‚˜ì´: {children_ages}")
    if basic_living is not None:
        user_info.append(f"ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ ì—¬ë¶€: {basic_living}")
    if employment_status is not None:
        user_info.append(f"ì·¨ì—… ì—¬ë¶€: {employment_status}")
    
        
    user_info_str = "\n".join(user_info)

    prompt = f"""í•œêµ­ ë³µì§€ì •ì±… ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ì ì •ë³´ì™€ ì¤‘ìš” ì§€ì¹¨ê³¼ ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ë³µì§€ ì •ì±…ë“¤ì„ ì •í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì: 
{user_info_str if user_info_str else "ì •ë³´ ì—†ìŒ"}

ì§ˆë¬¸: 
{question}

ê²€ìƒ‰ ê²°ê³¼:
{context}

ì¤‘ìš” ì§€ì¹¨:
1. ì •í™•íˆ 3ê°œ ì •ì±…ë§Œ ë‹µë³€
2. ê° ì •ì±…ë§ˆë‹¤ ì•„ë˜ 6ê°œ í•­ëª©ì„ ëª¨ë‘ ì‘ì„±
3. ë§ˆì§€ë§‰ì— ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬

í•„ìˆ˜ í˜•ì‹:
### ì •ì±… [ë²ˆí˜¸]: [ì •ì±…ëª…]
- ìš”ì•½: [ìš”ì•½ ë‚´ìš©]
- ëŒ€ìƒ: [ëŒ€ìƒ ë‚´ìš©]
- ì§€ì›: [ì§€ì› ë‚´ìš©]
- ë°©ë²•: [ë°©ë²• ë‚´ìš©]
- ì£¼ì˜: [ì£¼ì˜ ë‚´ìš©]
- ë¬¸ì˜: [ë¬¸ì˜ ë‚´ìš©]

ë‹µë³€"""

    return prompt, None, sources, search_results

# ë‹µë³€ì—ì„œ í”„ë¡¬í”„íŠ¸ ì œê±° í•¨ìˆ˜
def _extract_answer_only(response):
    """LLM ì‘ë‹µì—ì„œ ë‹µë³€ ë¶€ë¶„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not response:
        return response
    
    # "ë‹µë³€" í‚¤ì›Œë“œ ì´í›„ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
    answer_markers = ["ë‹µë³€:", "ë‹µë³€", "Answer:", "Answer"]
    
    for marker in answer_markers:
        if marker in response:
            parts = response.split(marker, 1)
            if len(parts) > 1:
                return parts[1].strip()
    
    # ë‹µë³€ ë§ˆì»¤ê°€ ì—†ìœ¼ë©´ ### ì •ì±…ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ë¶€í„° ì¶”ì¶œ
    lines = response.split('\n')
    answer_lines = []
    start_found = False
    
    for line in lines:
        if line.strip().startswith('### ì •ì±…'):
            start_found = True
        if start_found:
            answer_lines.append(line)
    
    if answer_lines:
        return '\n'.join(answer_lines)
    
    # ê·¸ë˜ë„ ì°¾ì§€ ëª»í•˜ë©´ ì›ë³¸ ë°˜í™˜
    return response

# ì¼ë°˜ ëª¨ë“œ ë‹µë³€ ìƒì„± í•¨ìˆ˜
def generate_answer(question, age=None, gender=None, location=None, income=None, family_size=None, marriage=None, children=None, children_ages=None, basic_living=None, employment_status=None, pregnancy_status=None, nationality=None, disability=None, military_service=None):
    """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ (ì¼ë°˜ ëª¨ë“œ)."""
    try:
        prompt, error_msg, sources, search_results = _process_query(question, age, gender, location, income, family_size, marriage, children, children_ages, basic_living, employment_status, pregnancy_status, nationality, disability, military_service)
        
        if error_msg:
            return error_msg, [], []
        
        # LLM ì‘ë‹µ ìƒì„±
        try:
            response = st.session_state.llm.predict(prompt)
            if response is None:
                return "ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", [], []
            
            # ë‹µë³€ì—ì„œ í”„ë¡¬í”„íŠ¸ ì œê±°
            clean_response = _extract_answer_only(response)
            clean_response = remove_emojis_and_enclosed_chars(clean_response)
            return clean_response, sources, search_results
            
        except Exception as e:
            return f"LLM ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [], []

    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [], []

# ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ë‹µë³€ ìƒì„± í•¨ìˆ˜
def generate_answer_streaming(question, age=None, gender=None, location=None, income=None):
    """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)."""
    try:
        prompt, error_msg, sources, search_results = _process_query(question, age, gender, location, income)
        
        if error_msg:
            yield error_msg, [], []
            return
        
        # LLM ì‘ë‹µ ìƒì„±
        try:
            response = st.session_state.llm.predict(prompt)
            if response is None:
                yield "ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", [], []
                return
            
            # ë‹µë³€ì—ì„œ í”„ë¡¬í”„íŠ¸ ì œê±°
            clean_response = _extract_answer_only(response)
            
            clean_response = remove_emojis_and_enclosed_chars(clean_response)
            # ìŠ¤íŠ¸ë¦¬ë° ì‹œë®¬ë ˆì´ì…˜
            words = clean_response.split()
            for i in range(0, len(words), 5):  # 5ë‹¨ì–´ì”© ì¶œë ¥
                yield " ".join(words[:i+5]), sources, search_results
                time.sleep(0.1)
                
        except Exception as e:
            yield f"LLM ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [], []

    except Exception as e:
        yield f"ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [], []

# í”¼ë“œë°± ì²˜ë¦¬ í•¨ìˆ˜
def on_feedback(feedback, chat_history_id: str = "", history_index: int = -1):
    """í”¼ë“œë°±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    reason = feedback.get("text", "")
    score = feedback.get("score", 0)
    
    # í”¼ë“œë°± ì €ì¥ ë¡œì§ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥)
    if "feedback_history" not in st.session_state:
        st.session_state.feedback_history = []
    
    st.session_state.feedback_history.append({
        "chat_history_id": chat_history_id,
        "history_index": history_index,
        "score": score,
        "reason": reason,
        "timestamp": time.time()
    })
    
    st.session_state["need_rerun"] = True

# ì±„íŒ… ì„¸ì…˜ ë³€ê²½ í•¨ìˆ˜
def on_chat_change():
    """ì±„íŒ… ì„¸ì…˜ì´ ë³€ê²½ë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤."""
    st.session_state.chat_box.use_chat_name(st.session_state["chat_name"])
    st.session_state.chat_box.context_to_session()

# ë©”ì¸ ì•±
def main():
    st.set_page_config(
        page_title="ë³µì§€PT",
        page_icon="ğŸ›ï¸",
        layout="wide"
    )
    
    # ChatBox ì´ˆê¸°í™”
    if "chat_box" not in st.session_state:
        st.session_state.chat_box = ChatBox(
            use_rich_markdown=False,
            user_theme="green",
            assistant_theme="blue",
        )
        st.session_state.chat_box.use_chat_name("welfare_chat")
    
    chat_box = st.session_state.chat_box
    
    # ì‚¬ì´ë“œë°” êµ¬ì„±
    with st.sidebar:        
        # ì±„íŒ… ì„¸ì…˜ ì„ íƒ
        chat_name = st.selectbox(
            "ì±„íŒ… ì„¸ì…˜:", 
            ["welfare_chat", "general_chat"], 
            key="chat_name", 
            on_change=on_chat_change
        )
        chat_box.use_chat_name(chat_name)
        
        # ì„¤ì • ì˜µì…˜
        streaming = st.checkbox('ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ', key="streaming")
        show_history = st.checkbox('ì„¸ì…˜ ìƒíƒœ ë³´ê¸°', key="show_history")
        
        chat_box.context_from_session(exclude=["chat_name"])
        
        st.divider()
        
        # ì‚¬ìš©ì ì •ë³´ ì…ë ¥
        st.subheader("ì‚¬ìš©ì ì •ë³´")
        age = st.text_input("ë‚˜ì´", value="", placeholder="ë‚˜ì´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        gender = st.radio("ì„±ë³„", options=["ë‚¨", "ì—¬"], index=0)
        family_size = ["1ì¸ ê°€êµ¬", "í•œë¶€ëª¨ê°€ì¡±", "ë‹¤ìë…€ê°€ì •"]
        family_size = st.selectbox("ê°€êµ¬ í˜•íƒœ", options=family_size, index=0)
        
        # ê²°í˜¼ ìœ ë¬´ ì…ë ¥
        marriage = ["ë¯¸í˜¼", "ê¸°í˜¼", "ì´í˜¼"]
        marriage = st.selectbox("ê²°í˜¼ ìœ ë¬´", options=marriage, index=0)
        
        # êµ­ì  ì…ë ¥
        nationality = ["ë‚´êµ­ì¸", "ì™¸êµ­ì¸", "ì¬ì™¸êµ­ë¯¼", "ë‚œë¯¼"]
        nationality = st.selectbox("êµ­ì ", options=nationality, index=0)
        
        # ì¥ì•  ìœ ë¬´ ì…ë ¥
        disability = st.radio("ì¥ì•  ìœ ë¬´", options=["ì—†ìŒ", "ìˆìŒ"], index=0)
        
        # ë³‘ì—­ ìœ ë¬´ ì…ë ¥
        military_service = ["í•´ë‹¹ ì—†ìŒ", "ë³µë¬´ ì™„ë£Œ", "ë³µë¬´ ì¤‘", "ë¯¸í•„"]
        military_service = st.selectbox("ë³‘ì—­ ìœ ë¬´", options=military_service, index=0)
        
        # ì·¨ì—… ì—¬ë¶€ (ì‹¤ì§ì/êµ¬ì§ì/ì¬ì§ì)
        employment_status = ["ì‹¤ì§ì", "êµ¬ì§ì", "ì¬ì§ì"]
        employment_status = st.selectbox("ì·¨ì—… ì—¬ë¶€", options=employment_status, index=0)
        
        # ì„ì‹ /ì¶œì‚° ìƒíƒœ (ì„ì‚°ë¶€, ì¶œì‚° í›„ 6ê°œì›” ì´ë‚´, í•´ë‹¹ ì—†ìŒ)
        pregnancy_status = ["í•´ë‹¹ ì—†ìŒ", "ì„ì‚°ë¶€", "ì¶œì‚° í›„ 6ê°œì›” ì´ë‚´"]
        pregnancy_status = st.selectbox("ì„ì‹ /ì¶œì‚°", options=pregnancy_status, index=0)
        
        # ìë…€ ìˆ˜ ì„ íƒ
        children_options = ["0ëª…", "1ëª…", "2ëª…", "3ëª…", "4ëª…", "5ëª…", "6ëª…", "7ëª…", "8ëª…", "9ëª…", "10ëª…"]
        children = st.selectbox("ìë…€ ìˆ˜", options=children_options, index=0)

        # ìë…€ ë‚˜ì´ ì…ë ¥: ìë…€ ìˆ˜ê°€ 1ëª… ì´ìƒì¼ ë•Œë§Œ ì…ë ¥ í•„ë“œ í™œì„±í™”
        children_ages = []
        if children != "0ëª…":
            # ìë…€ ìˆ˜ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
            num_children = int(children.replace("ëª…", ""))
            age_options = ["0ì„¸", "1ì„¸", "2ì„¸", "3ì„¸", "4ì„¸", "5ì„¸", "6ì„¸", "7ì„¸", "8ì„¸", "9ì„¸", "10ì„¸", "11ì„¸", "12ì„¸", "13ì„¸", "14ì„¸", "15ì„¸", "16ì„¸", "17ì„¸", "18ì„¸"]
            st.markdown("ìë…€ë³„ ë‚˜ì´ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            for i in range(num_children):
                age = st.selectbox(
                    f"ìë…€ {i+1} ë‚˜ì´", 
                    options=age_options, 
                    index=0, 
                    key=f"children_age_{i}"
                )
                children_ages.append(age)
        # ê±°ì£¼ì§€
        locations = ["ì„œìš¸", "ìˆ˜ì›", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…", 
                    "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼"]
        location = st.selectbox("ê±°ì£¼ì§€", options=locations, index=0)
        
        # ì†Œë“ (ì¤‘ìœ„ %)
        income = st.slider("ì†Œë“ (ì¤‘ìœ„ %)", min_value=10, max_value=90, value=50, step=1)
        
        # ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ ì—¬ë¶€ (ìˆ˜ê¸‰ì/ë¹„ìˆ˜ê¸‰ì)
        basic_living = st.radio("ê¸°ì´ˆìƒí™œìˆ˜ê¸‰ ì—¬ë¶€", options=["ë¹„ìˆ˜ê¸‰ì", "ìˆ˜ê¸‰ì"], index=0)
        
        st.divider()
        
        # PDF ì—…ë¡œë“œ
        st.subheader("PDF ë¬¸ì„œ ì—…ë¡œë“œ")
        uploaded_files = st.file_uploader(
            "ë³µì§€ ì •ì±… PDF íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œ ê¸°ì¤€ ìµœì‹  ë¬¸ì„œë¡œ ì—…ë¡œë“œë©ë‹ˆë‹¤)",
            type=["pdf"],
            accept_multiple_files=True
        )
        
        import os  # os ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ì„ íƒìƒ‰í•©ë‹ˆë‹¤.

        # ë¬¸ì„œ ë¡œë“œ/ì—…ë°ì´íŠ¸ ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘
        if st.button("ë¬¸ì„œ ë¡œë“œ/ì—…ë°ì´íŠ¸"):
            with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    file_paths = []

                    # ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆìœ¼ë©´ ì €ì¥
                    if uploaded_files:
                        for uploaded_file in uploaded_files:
                            with open(uploaded_file.name, "wb") as f:
                                f.write(uploaded_file.getvalue())
                            file_paths.append(uploaded_file.name)
                    else:
                        # ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ./pdf í´ë” ë‚´ ëª¨ë“  PDF íŒŒì¼ì„ ë¶ˆëŸ¬ì˜´
                        pdf_dir = "./pdf/welfare"
                        if not os.path.exists(pdf_dir):
                            st.error("pdf í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € pdf í´ë”ë¥¼ ìƒì„±í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                            return
                        pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]
                        if not pdf_files:
                            st.error("pdf í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í´ë”ì— PDFë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
                            return
                        file_paths = pdf_files

                    # ë¬¸ì„œ ë¡œë“œ ë° ì²˜ë¦¬
                    texts = load_and_process_documents(file_paths)
                    
                    if texts:
                        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
                        if "embedding_model" not in st.session_state:
                            try:
                                st.session_state.embedding_model = load_embedding_model()
                            except Exception as e:
                                st.error(f"ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                                return
                        
                        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
                        try:
                            db = create_vectorstore(texts, st.session_state.embedding_model)
                            st.session_state.db = db
                        except Exception as e:
                            st.error(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                            return
                        
                        # LLM ëª¨ë¸ ë¡œë“œ
                        if "llm" not in st.session_state:
                            try:
                                st.session_state.llm = load_llm_model()
                            except Exception as e:
                                st.error(f"LLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                                return
                        
                        st.success(f"âœ… {len(texts)}ê°œ ë¬¸ì„œ ì²­í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.session_state.documents_loaded = True
                    else:
                        st.error("ë¬¸ì„œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        # ìƒíƒœ í‘œì‹œ
        if st.session_state.get("documents_loaded", False):
            st.success("âœ… ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
        else:
            st.warning("âš ï¸ PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ pdf í´ë”ì— íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”(ì„ íƒ)")
        
        st.divider()
        
        # ë‚´ë³´ë‚´ê¸° ë²„íŠ¼
        btns = st.container()
        
        if btns.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì‚­ì œ"):
            chat_box.init_session(clear=True)
            st.rerun()
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    # ë©‹ì§„ ì²« í™”ë©´ ë¬¸êµ¬ì™€ í°íŠ¸ í¬ê¸° ì¡°ì •
    st.markdown(
        """
        <h1 style='text-align: center; font-size: 3.2em;'>ğŸ›ï¸ ë³µì§€PTì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!</h1>
        <p style='text-align: center; font-size: 1.5em; color: #555;'>
            ë‹¹ì‹ ì˜ ìƒí™©ì— ê¼­ ë§ëŠ” ë³µì§€ ì •ì±…ì„ <b>AI</b>ê°€ ì‰½ê³  ë¹ ë¥´ê²Œ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.<br>
            ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ì…ë ¥í•´ë³´ì„¸ìš”!
        </p>
        """,
        unsafe_allow_html=True
    )
    
    # ì±„íŒ… ë°•ìŠ¤ ì´ˆê¸°í™” ë° ì¶œë ¥
    chat_box.init_session()
    chat_box.output_messages()
    
    # í”¼ë“œë°± ì„¤ì •
    feedback_kwargs = {
        "feedback_type": "thumbs",
        "optional_text_label": "í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”",
    }
    
    # ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
    if query := st.chat_input('ë‚˜ì—ê²Œ ì•Œë§ëŠ” ë³µì§€ í˜œíƒ ì•Œë ¤ì£¼ì„¸ìš”.'):
        if not st.session_state.get("documents_loaded", False):
            st.error("ë¨¼ì € PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            return
        

        chat_box.user_say(query)
        
        age_val = age if age.strip() else None
        
        if streaming:
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            try:
                # ë‹µë³€ ë° ì°¸ê³ ìë£Œ ì˜ì—­ì„ í…ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
                elements = chat_box.ai_say([
                    "ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                    "",
                ])
                
                generator = generate_answer_streaming(
                    question=query,
                    age=age_val,
                    gender=gender,
                    location=location,
                    income=income,
                    family_size=family_size,
                    marriage=marriage,
                    children=children,
                    children_ages=children_ages,
                    employment_status=employment_status,
                    pregnancy_status=pregnancy_status,
                    nationality=nationality,
                    disability=disability,
                    military_service=military_service,
                    basic_living=basic_living
                )
                
                text = ""
                sources = []
                search_results = []
                try:
                    for response, doc_sources, doc_search_results in generator:
                        text = response
                        sources = doc_sources
                        search_results = doc_search_results
                        chat_box.update_msg(text, element_index=0, streaming=True)
                except Exception as e:
                    text = f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                    sources = []
                    search_results = []
                
                chat_box.update_msg(text, element_index=0, streaming=False, state="complete")
                
                # ê²€ìƒ‰ ê²°ê³¼ì™€ ì°¸ê³ ìë£Œ í‘œì‹œ
                reference_text = ""
                if search_results:
                    reference_text += "ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´:\n\n"
                    for i, result in enumerate(search_results, 1):
                        reference_text += f"{i}. {os.path.basename(result['source'])} (í˜ì´ì§€ {result['page']})\n"
                        reference_text += f"{result['content']}\n\n"
                    reference_text += "---\n\n"
                
                if sources:
                    reference_text += "ì°¸ê³ ìë£Œ:\n" + "\n".join(sources)
                else:
                    reference_text += "ì°¸ê³ ìë£Œ: ì—†ìŒ"
                
                chat_box.update_msg(reference_text, element_index=1, streaming=False, state="complete")
                
                # í”¼ë“œë°± í‘œì‹œ
                chat_history_id = f"chat_{len(chat_box.history)}"
                chat_box.show_feedback(
                    **feedback_kwargs,
                    key=chat_history_id,
                    on_submit=on_feedback,
                    kwargs={"chat_history_id": chat_history_id, "history_index": len(chat_box.history) - 1}
                )
            except Exception as e:
                chat_box.ai_say([
                    f"ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì˜¤ë¥˜: {str(e)}",
                    "ğŸ“„ ì°¸ê³ ìë£Œ: ì—†ìŒ",
                ])
        else:
            # ì¼ë°˜ ëª¨ë“œ
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    result = generate_answer(
                        question=query,
                        age=age_val,
                        gender=gender,
                        location=location,
                        income=income,
                        family_size=family_size,
                        basic_living=basic_living,
                        marriage=marriage,
                        children=children,
                        children_ages=children_ages,
                        employment_status=employment_status,
                        pregnancy_status=pregnancy_status,
                        nationality=nationality,
                        disability=disability,
                        military_service=military_service
                    )
                    # ë°˜í™˜ê°’ì´ tupleì¸ì§€ í™•ì¸
                    if isinstance(result, tuple) and len(result) == 3:
                        text, sources, search_results = result
                    else:
                        text = str(result)
                        sources = []
                        search_results = []

                    
                except Exception as e:
                    text = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    sources = []
                    search_results = []
            
            reference_text = ""
            reference_text += "---\n\n"            
            if search_results:
                reference_text += "ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´:\n\n"
                for i, result in enumerate(search_results, 1):
                    reference_text += f"{i}. {os.path.basename(result['source'])} (í˜ì´ì§€ {result['page']})\n"
                    reference_text += f"{result['content']}\n\n"
            
            # ë‹µë³€ê³¼ ì°¸ê³ ìë£Œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì œê³µí•©ë‹ˆë‹¤. (Markdownì´ ì•„ë‹Œ plain text)
            chat_box.ai_say([
                text,
                reference_text,
            ])
    
    # ì„¸ì…˜ ìƒíƒœ ë³´ê¸°
    if show_history:
        st.subheader("ì„¸ì…˜ ìƒíƒœ")
        st.write(st.session_state)

if __name__ == "__main__":
    main() 