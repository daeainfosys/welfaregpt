import time
import re
import os
from typing import List

import streamlit as st
from streamlit_chatbox import *

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.llms import HuggingFacePipeline
from transformers import AutoTokenizer, pipeline
import torch
from langchain.schema import Document
import unicodedata
from kiwipiepy import Kiwi
from langchain_community.vectorstores import FAISS
from langchain.retrievers import EnsembleRetriever
from langchain_community.retrievers import BM25Retriever
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory

# =====================================================
# ì „ì—­ ë³€ìˆ˜ ë° ìƒìˆ˜
# =====================================================

_kiwi = None

SIDO_CITY_MAP = {
    "ì„œìš¸": ["ì¢…ë¡œ", "ì¤‘êµ¬", "ìš©ì‚°", "ì„±ë™", "ê´‘ì§„", "ë™ëŒ€ë¬¸", "ì¤‘ë‘", "ì„±ë¶", "ê°•ë¶", "ë„ë´‰", "ë…¸ì›", "ì€í‰", "ì„œëŒ€ë¬¸", "ë§ˆí¬", "ì–‘ì²œ", "ê°•ì„œ", "êµ¬ë¡œ", "ê¸ˆì²œ", "ì˜ë“±í¬", "ë™ì‘", "ê´€ì•…", "ì„œì´ˆ", "ê°•ë‚¨", "ì†¡íŒŒ", "ê°•ë™"],
    "ë¶€ì‚°": ["ì¤‘êµ¬", "ì„œêµ¬", "ë™êµ¬", "ì˜ë„êµ¬", "ë¶€ì‚°ì§„êµ¬", "ë™ë˜êµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "í•´ìš´ëŒ€êµ¬", "ì‚¬í•˜êµ¬", "ê¸ˆì •êµ¬", "ê°•ì„œêµ¬", "ì—°ì œêµ¬", "ìˆ˜ì˜êµ¬", "ì‚¬ìƒêµ¬", "ê¸°ì¥êµ°"],
    "ëŒ€êµ¬": ["ì¤‘êµ¬", "ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "ìˆ˜ì„±êµ¬", "ë‹¬ì„œêµ¬", "ë‹¬ì„±êµ°"],
    "ì¸ì²œ": ["ì¤‘êµ¬", "ë™êµ¬", "ë¯¸ì¶”í™€êµ¬", "ì—°ìˆ˜êµ¬", "ë‚¨ë™êµ¬", "ë¶€í‰êµ¬", "ê³„ì–‘êµ¬", "ì„œêµ¬", "ê°•í™”êµ°", "ì˜¹ì§„êµ°"],
    "ê´‘ì£¼": ["ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "ê´‘ì‚°êµ¬"],
    "ëŒ€ì „": ["ë™êµ¬", "ì¤‘êµ¬", "ì„œêµ¬", "ìœ ì„±êµ¬", "ëŒ€ë•êµ¬"],
    "ìš¸ì‚°": ["ì¤‘êµ¬", "ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ìš¸ì£¼êµ°"],
    "ì„¸ì¢…": ["ì„¸ì¢…"],
    "ê²½ê¸°ë„": ["ìˆ˜ì›", "ì„±ë‚¨", "ê³ ì–‘", "ìš©ì¸", "ë¶€ì²œ", "ì•ˆì‚°", "ì•ˆì–‘", "ë‚¨ì–‘ì£¼", "í™”ì„±", "í‰íƒ", "ì˜ì •ë¶€", "ì‹œí¥", "íŒŒì£¼", "ê¹€í¬", "ê´‘ëª…", "ê´‘ì£¼", "êµ°í¬", "ì˜¤ì‚°", "ì´ì²œ", "ì•ˆì„±", "ì–‘ì£¼", "êµ¬ë¦¬", "í¬ì²œ", "ì˜ì™•", "í•˜ë‚¨", "ì—¬ì£¼", "ë™ë‘ì²œ", "ê³¼ì²œ", "ê°€í‰", "ì—°ì²œ"],
    "ê°•ì›ë„": ["ì¶˜ì²œ", "ì›ì£¼", "ê°•ë¦‰", "ë™í•´", "íƒœë°±", "ì†ì´ˆ", "ì‚¼ì²™", "í™ì²œ", "íš¡ì„±", "ì˜ì›”", "í‰ì°½", "ì •ì„ ", "ì² ì›", "í™”ì²œ", "ì–‘êµ¬", "ì¸ì œ", "ê³ ì„±", "ì–‘ì–‘"],
    "ì¶©ì²­ë¶ë„": ["ì²­ì£¼", "ì¶©ì£¼", "ì œì²œ", "ë³´ì€", "ì˜¥ì²œ", "ì˜ë™", "ì§„ì²œ", "ê´´ì‚°", "ìŒì„±", "ë‹¨ì–‘", "ì¦í‰"],
    "ì¶©ì²­ë‚¨ë„": ["ì²œì•ˆ", "ê³µì£¼", "ë³´ë ¹", "ì•„ì‚°", "ì„œì‚°", "ë…¼ì‚°", "ê³„ë£¡", "ë‹¹ì§„", "ê¸ˆì‚°", "ë¶€ì—¬", "ì„œì²œ", "ì²­ì–‘", "í™ì„±", "ì˜ˆì‚°", "íƒœì•ˆ"],
    "ì „ë¼ë¶ë„": ["ì „ì£¼", "êµ°ì‚°", "ìµì‚°", "ì •ì", "ë‚¨ì›", "ê¹€ì œ", "ì™„ì£¼", "ì§„ì•ˆ", "ë¬´ì£¼", "ì¥ìˆ˜", "ì„ì‹¤", "ìˆœì°½", "ê³ ì°½", "ë¶€ì•ˆ"],
    "ì „ë¼ë‚¨ë„": ["ëª©í¬", "ì—¬ìˆ˜", "ìˆœì²œ", "ë‚˜ì£¼", "ê´‘ì–‘", "ë‹´ì–‘", "ê³¡ì„±", "êµ¬ë¡€", "ê³ í¥", "ë³´ì„±", "í™”ìˆœ", "ì¥í¥", "ê°•ì§„", "í•´ë‚¨", "ì˜ì•”", "ë¬´ì•ˆ", "í•¨í‰", "ì˜ê´‘", "ì¥ì„±", "ì™„ë„", "ì§„ë„", "ì‹ ì•ˆ"],
    "ê²½ìƒë¶ë„": ["í¬í•­", "ê²½ì£¼", "ê¹€ì²œ", "ì•ˆë™", "êµ¬ë¯¸", "ì˜ì£¼", "ì˜ì²œ", "ìƒì£¼", "ë¬¸ê²½", "ê²½ì‚°", "êµ°ìœ„", "ì˜ì„±", "ì²­ì†¡", "ì˜ì–‘", "ì˜ˆì²œ", "ë´‰í™”", "ìš¸ì§„", "ìš¸ë¦‰"],
    "ê²½ìƒë‚¨ë„": ["ì°½ì›", "ì§„ì£¼", "í†µì˜", "ì‚¬ì²œ", "ê¹€í•´", "ë°€ì–‘", "ê±°ì œ", "ì–‘ì‚°", "ì˜ë ¹", "í•¨ì•ˆ", "ì°½ë…•", "ê³ ì„±", "ë‚¨í•´", "í•˜ë™", "ì‚°ì²­", "í•¨ì–‘", "ê±°ì°½", "í•©ì²œ"],
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„": ["ì œì£¼ì‹œ", "ì„œê·€í¬ì‹œ"]
}

FOLLOWUP_KEYWORDS = [
    "ì–´ë–»ê²Œ", "ë°©ë²•", "ì ˆì°¨", "ì‹ ì²­", "ì ‘ìˆ˜", "ìê²©", "ì¡°ê±´", "ìš”ê±´", 
    "ì„œë¥˜", "ë¬¸ì„œ", "ì¤€ë¹„", "í•„ìš”", "ì–¸ì œ", "ì–´ë””ì„œ", "ëˆ„êµ¬", "ì–¼ë§ˆ",
    "ìì„¸íˆ", "ë”", "êµ¬ì²´ì ", "ìƒì„¸", "ì¶”ê°€", "ì •í™•", "ì •í™•íˆ",
    "ê·¸ ì •ì±…", "í•´ë‹¹ ì •ì±…", "ìœ„ ì •ì±…", "ì´ ì •ì±…", "ê·¸ê²ƒ", "ê·¸ê±°", "ì´ê²ƒ", "ì´ê±°",
    "ì²« ë²ˆì§¸", "ë‘ ë²ˆì§¸", "ì„¸ ë²ˆì§¸", "1ë²ˆ", "2ë²ˆ", "3ë²ˆ"
]

# =====================================================
# ì±„íŒ… ê´€ë¦¬ í´ë˜ìŠ¤
# =====================================================

class ChatManager:
    @staticmethod
    def get_chat_list():
        """ì±„íŒ… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if "chat_list" not in st.session_state:
            st.session_state.chat_list = ["welfare_chat"]
        return st.session_state.chat_list

    @staticmethod
    def add_new_chat():
        """ìƒˆ ì±„íŒ…ì„ ëª©ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if "chat_list" not in st.session_state:
            st.session_state.chat_list = ["welfare_chat"]
        
        if "max_chat_number" not in st.session_state:
            st.session_state.max_chat_number = 0
        
        st.session_state.max_chat_number += 1
        new_chat_name = f"ìƒˆ ì±„íŒ… {st.session_state.max_chat_number}"
        st.session_state.chat_list.append(new_chat_name)
        return new_chat_name

    @staticmethod
    def delete_chat(chat_name):
        """ì±„íŒ…ì„ ëª©ë¡ì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤."""
        if "chat_list" not in st.session_state or chat_name not in st.session_state.chat_list:
            return
            
        st.session_state.chat_list.remove(chat_name)
        
        # ê´€ë ¨ ë©”ëª¨ë¦¬ ì •ë¦¬
        MemoryManager.cleanup_chat_data(chat_name)
        
        # í˜„ì¬ ì±„íŒ…ì´ ì‚­ì œëœ ê²½ìš° ì²˜ë¦¬
        if st.session_state.get("current_chat") == chat_name:
            if st.session_state.chat_list:
                st.session_state.current_chat = st.session_state.chat_list[0]
                st.session_state.chat_box.use_chat_name(st.session_state.current_chat)
            else:
                st.session_state.chat_list = ["welfare_chat"]
                st.session_state.current_chat = "welfare_chat"
                st.session_state.chat_box.use_chat_name("welfare_chat")

    @staticmethod
    def start_new_chat():
        """ìƒˆ ì±„íŒ…ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
        new_chat_name = ChatManager.add_new_chat()
        st.session_state.current_chat = new_chat_name
        st.session_state.chat_box.use_chat_name(new_chat_name)
        st.session_state.chat_box.init_session(clear=True)
        
        # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        MemoryManager.clear_conversation_memory(new_chat_name)
        MemoryManager.save_policy_context(new_chat_name, [])
        
        st.session_state.chat_started = False
        st.rerun()

# =====================================================
# ë©”ëª¨ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤
# =====================================================

class MemoryManager:
    @staticmethod
    def get_conversation_memory(chat_name):
        """ì±„íŒ…ë³„ ConversationBufferMemory ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        memory_key = f"memory_{chat_name}"
        if memory_key not in st.session_state:
            st.session_state[memory_key] = ConversationBufferMemory(
                memory_key="chat_history",
                input_key="question",
                output_key="text",
                return_messages=False,
                max_token_limit=2000,
            )
        return st.session_state[memory_key]

    @staticmethod
    def get_conversation_history(chat_name):
        """ì±„íŒ…ë³„ ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        memory = MemoryManager.get_conversation_memory(chat_name)
        chat_memory = memory.chat_memory
        
        history = []
        messages = chat_memory.messages
        
        for i in range(0, len(messages), 2):
            if i + 1 < len(messages):
                human_msg = messages[i]
                ai_msg = messages[i + 1]
                history.append({
                    "question": human_msg.content,
                    "answer": ai_msg.content,
                    "timestamp": time.time()
                })
        
        return history

    @staticmethod
    def clear_conversation_memory(chat_name):
        """íŠ¹ì • ì±„íŒ…ì˜ ëŒ€í™” ê¸°ë¡ì„ ì§€ì›ë‹ˆë‹¤."""
        memory = MemoryManager.get_conversation_memory(chat_name)
        memory.clear()

    @staticmethod
    def save_policy_context(chat_name, policies_info):
        """ì±„íŒ…ë³„ë¡œ ì œì‹œëœ ì •ì±… ì •ë³´ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        context_key = f"policy_context_{chat_name}"
        st.session_state[context_key] = policies_info

    @staticmethod
    def get_policy_context(chat_name):
        """ì±„íŒ…ë³„ ì •ì±… ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        context_key = f"policy_context_{chat_name}"
        return st.session_state.get(context_key, [])

    @staticmethod
    def cleanup_chat_data(chat_name):
        """ì±„íŒ… ê´€ë ¨ ëª¨ë“  ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        keys_to_remove = [
            f"memory_{chat_name}",
            f"policy_context_{chat_name}"
        ]
        for key in keys_to_remove:
            if key in st.session_state:
                del st.session_state[key]

# =====================================================
# í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
# =====================================================

class TextProcessor:
    @staticmethod
    def remove_emojis_and_special_chars(text):
        """í…ìŠ¤íŠ¸ì—ì„œ ì´ëª¨ì§€ì™€ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        return ''.join(
            ch for ch in text
            if not (
                unicodedata.category(ch).startswith('So')
                or (0x1F000 <= ord(ch) <= 0x1FFFF)
                or (0x2460 <= ord(ch) <= 0x24FF)
            )
        )

    @staticmethod
    def find_region_in_text(text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        city_to_sido = {city: sido for sido, cities in SIDO_CITY_MAP.items() for city in cities}
        
        cleaned_text = re.sub(r'[_\.]', ' ', text.lower())
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
        
        # ê¸ˆì§€ ë¬¸êµ¬ ì œê±°
        banned_phrases = ["ë¬´ì£¼íƒì", "ë¬´ì£¼íƒ ì„¸ëŒ€", "ë¬´ì£¼íƒì„¸ëŒ€êµ¬ì„±ì›", "ë¬´ì£¼íƒ", "ì£¼íƒë„ì‹œê¸°ê¸ˆ", "ì£¼íƒê³µê¸‰", "ì£¼íƒê±´ì„¤", "ì£¼íƒê´€ë¦¬"]
        for phrase in banned_phrases:
            cleaned_text = cleaned_text.replace(phrase, " ")
        
        # ì‹œêµ°êµ¬ ìš°ì„  ë§¤ì¹­
        for city in sorted(city_to_sido.keys(), key=len, reverse=True):
            pattern = rf'{re.escape(city)}(ì‹œ|êµ°|êµ¬)?'
            if re.search(pattern, cleaned_text):
                return city_to_sido[city]
        
        # ì‹œë„ ë§¤ì¹­
        for sido in sorted(SIDO_CITY_MAP.keys(), key=len, reverse=True):
            pattern = rf'{re.escape(sido)}(ê´‘ì—­ì‹œ|íŠ¹ë³„ì‹œ|ë„)?'
            if re.search(pattern, cleaned_text):
                return sido
        
        return "ì „êµ­"

    @staticmethod
    def preprocess_document(text):
        """ë¬¸ì„œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        text = TextProcessor.remove_emojis_and_special_chars(text)
        text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
        text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
        text = re.sub(r'(\*\*|\*|_)', '', text)
        text = re.sub(r'^[-\*\+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'<[^>]+>', '', text)
        text = re.sub(r'\n+', '\n', text).strip()
        return text

    @staticmethod
    def clean_text(text):
        """HTML íƒœê·¸ì™€ ê³µë°±ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        text = re.sub(r'<[^>]+>', '', text)
        return re.sub(r'\s+', ' ', text.strip())

    @staticmethod
    def extract_answer_only(response):
        """LLM ì‘ë‹µì—ì„œ ë‹µë³€ ë¶€ë¶„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not response:
            return response

        answer_markers = ["ë‹µë³€:", "ë‹µë³€", "Answer:", "Answer"]
        
        for marker in answer_markers:
            if marker in response:
                parts = response.split(marker, 1)
                if len(parts) > 1:
                    answer = parts[1].strip()
                    break
        else:
            lines = response.split('\n')
            answer_lines = []
            start_found = False

            for line in lines:
                if line.strip().startswith('### ì •ì±…: '):
                    start_found = True
                if start_found:
                    answer_lines.append(line)

            answer = '\n'.join(answer_lines) if answer_lines else response

        # ê°ì‚¬ ì¸ì‚¬ ì œê±°
        thank_you_markers = ["ê°ì‚¬í•©ë‹ˆë‹¤.", "ê°ì‚¬í•©ë‹ˆë‹¤", "Thank you.", "Thank you"]
        for marker in thank_you_markers:
            if marker in answer:
                answer = answer.split(marker, 1)[0].strip()
                break

        return answer

# =====================================================
# í›„ì† ì§ˆë¬¸ ì²˜ë¦¬ í´ë˜ìŠ¤
# =====================================================

class FollowupHandler:
    @staticmethod
    def is_followup_question(question, chat_history):
        """í›„ì† ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
        question_lower = question.lower()
        has_previous_policy = "ì •ì±…" in chat_history
        has_followup_keyword = any(keyword in question_lower for keyword in FOLLOWUP_KEYWORDS)
        return has_previous_policy and has_followup_keyword

    @staticmethod
    def extract_referenced_policy(question, chat_history):
        """ì§ˆë¬¸ì—ì„œ ì°¸ì¡°í•˜ëŠ” ì •ì±…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        question_lower = question.lower()
        
        # ìˆ«ìë¡œ ì •ì±…ì„ ì°¸ì¡°í•˜ëŠ” ê²½ìš°
        policy_patterns = {
            ("1ë²ˆ", "ì²« ë²ˆì§¸"): r'### ì •ì±… 1: ([^\n]+)',
            ("2ë²ˆ", "ë‘ ë²ˆì§¸"): r'### ì •ì±… 2: ([^\n]+)',
            ("3ë²ˆ", "ì„¸ ë²ˆì§¸"): r'### ì •ì±… 3: ([^\n]+)'
        }
        
        for keywords, pattern in policy_patterns.items():
            if any(keyword in question_lower for keyword in keywords):
                policy_match = re.search(pattern, chat_history)
                if policy_match:
                    return f"### ì •ì±… {keywords[0][0]}: {policy_match.group(1)}"
        
        # ì¼ë°˜ì ì¸ ì°¸ì¡°ì˜ ê²½ìš° ê°€ì¥ ìµœê·¼ ì •ì±… ë°˜í™˜
        policies = re.findall(r'### ì •ì±… \d+: [^\n]+(?:\n- [^\n]+)*', chat_history)
        return policies[-1] if policies else ""

# =====================================================
# Kiwi í† í¬ë‚˜ì´ì € í´ë˜ìŠ¤
# =====================================================

class KiwiTokenizer:
    @staticmethod
    def get_instance():
        """Kiwi ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹±ê¸€í†¤ìœ¼ë¡œ ê´€ë¦¬"""
        global _kiwi
        if _kiwi is None:
            _kiwi = Kiwi()
        return _kiwi

    @staticmethod
    def tokenize(text):
        """ìµœì í™”ëœ Kiwi í† í°í™” í•¨ìˆ˜"""
        if not text or not text.strip():
            return []
        
        kiwi = KiwiTokenizer.get_instance()
        try:
            if len(text) > 1000:
                text = text[:1000]
            
            tokens = kiwi.tokenize(text)
            return [token.form for token in tokens if len(token.form) > 1]
        except Exception:
            return [word for word in text.split() if len(word) > 1]

# =====================================================
# ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤
# =====================================================

class DocumentProcessor:
    @staticmethod
    def process_pages_with_region(pages: List[Document]) -> List[Document]:
        """í˜ì´ì§€ì— ì§€ì—­ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        new_docs = []
        for page in pages:
            content = TextProcessor.preprocess_document(page.page_content)
            
            file_region = TextProcessor.find_region_in_text(page.metadata.get('source', ''))
            content_region = TextProcessor.find_region_in_text(content)
            region = file_region if file_region != "ì „êµ­" else content_region
            
            metadata = dict(page.metadata) if page.metadata else {}
            metadata["region"] = region
            new_docs.append(Document(page_content=content, metadata=metadata))
        return new_docs

    @staticmethod
    def load_and_process_documents(file_paths: List[str], embedding_model):
        """ì—¬ëŸ¬ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  EnsembleRetrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            all_documents = []
            for file_path in file_paths:
                loader = PyMuPDFLoader(file_path)
                documents = loader.load()
                all_documents.extend(documents)
            
            if not all_documents:
                return None, None, None
            processed_data = DocumentProcessor.process_pages_with_region(all_documents)
            
            KiwiTokenizer.get_instance()
            
            kiwi_bm25 = BM25Retriever.from_documents(
                processed_data, 
                preprocess_func=KiwiTokenizer.tokenize
            )
            kiwi_bm25.k = 5
            
            vectorstore = FAISS.from_documents(processed_data, embedding_model)
            faiss_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

            retriever = EnsembleRetriever(
                retrievers=[kiwi_bm25, faiss_retriever],
                weights=[0.5, 0.5]
            )

            return retriever, len(processed_data), processed_data
        except Exception as e:
            st.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, None, None

    @staticmethod
    def load_additional_documents(uploaded_files):
        """ì¶”ê°€ ë¬¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        pdf_dir = "./pdf/welfare"
        
        with st.spinner("ì¶”ê°€ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                additional_files = []
                for uploaded_file in uploaded_files:
                    with open(uploaded_file.name, "wb") as f:
                        f.write(uploaded_file.getvalue())
                    additional_files.append(uploaded_file.name)
                
                all_files = []
                if os.path.exists(pdf_dir):
                    pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]
                    all_files.extend(pdf_files)
                all_files.extend(additional_files)
                
                st.info(f"ê¸°ë³¸ ë¬¸ì„œ í¬í•¨ ì´ {len(all_files)}ê°œ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...")

                result = DocumentProcessor.load_and_process_documents(all_files, st.session_state.embedding_model)
                
                if result[0] is not None:
                    retriever, total_chunks, processed_docs = result
                    st.session_state.retriever = retriever
                    st.session_state.processed_docs = processed_docs
                    
                    st.success(f"âœ… ì¶”ê°€ ë¬¸ì„œ í¬í•¨ ì´ {len(all_files)}ê°œ ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.session_state.documents_loaded = True
                    return True
                else:
                    st.error("ì¶”ê°€ ë¬¸ì„œ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    return False
                    
            except Exception as e:
                st.error(f"ì¶”ê°€ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return False

    @staticmethod
    def load_default_documents():
        """í˜ì´ì§€ ì‹œì‘ ì‹œ ê¸°ë³¸ ë³µì§€ ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
        if st.session_state.get("default_documents_loaded", False):
            return
        
        pdf_dir = "./pdf/welfare"
        
        if os.path.exists(pdf_dir):
            pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]
            
            if pdf_files:
                try:
                    with st.spinner("ê¸°ë³¸ ë³µì§€ ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        if "embedding_model" not in st.session_state:
                            st.session_state.embedding_model = ModelLoader.load_embedding_model()
                        
                        result = DocumentProcessor.load_and_process_documents(pdf_files, st.session_state.embedding_model)
                        if result[0] is not None:
                            retriever, total_chunks, processed_docs = result
                            st.session_state.retriever = retriever
                            st.session_state.processed_docs = processed_docs
                            
                            if "chains" not in st.session_state:
                                st.session_state.chains = ModelLoader.load_llm_model()
                            
                            st.session_state.default_documents_loaded = True
                            st.session_state.documents_loaded = True
                            st.success(f"âœ… ê¸°ë³¸ ë³µì§€ ë¬¸ì„œ {total_chunks}ê°œ ì²­í¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
                            
                except Exception as e:
                    st.error(f"ê¸°ë³¸ ë¬¸ì„œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# =====================================================
# ëª¨ë¸ ë¡œë” í´ë˜ìŠ¤
# =====================================================

class ModelLoader:
    @staticmethod
    @st.cache_resource
    def load_embedding_model():
        """ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return HuggingFaceEmbeddings(
            model_name='jhgan/ko-sroberta-multitask',
            model_kwargs={'device': 'cuda'},
            encode_kwargs={'normalize_embeddings': True},
        )

    @staticmethod
    @st.cache_resource
    def load_llm_model():
        """LLM ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
        model_name = "MLP-KTLim/llama-3-Korean-Bllossom-8B"
        
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        
        llm_pipeline = pipeline(
            "text-generation",
            model=model_name,
            model_kwargs={"torch_dtype": torch.bfloat16},
            device_map="auto",
            max_new_tokens=1024,
            temperature=0.3,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            repetition_penalty=1.1,
        )
        llm = HuggingFacePipeline(pipeline=llm_pipeline)

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ë“¤
        policy_prompt = PromptTemplate(
            input_variables=["question", "context", "chat_history"],
            template="""ë‹¹ì‹ ì€ í•œêµ­ ë³µì§€ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì°¸ê³ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë³µì§€ ì •ì±…ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.

{chat_history}

[ì‚¬ìš©ì ì§ˆë¬¸]:
{question}

[ì°¸ê³ ìë£Œ]:
{context}

[ë‹µë³€ ì§€ì¹¨]:
1. ì´ì „ ëŒ€í™” ë‚´ìš©ì´ ìˆë‹¤ë©´ ê·¸ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ ì£¼ì„¸ìš”.
2. ìµœëŒ€ 3ê°œì˜ ê´€ë ¨ ì •ì±…ì„ ì¶”ì²œí•´ ì£¼ì„¸ìš”.
3. ê° ì •ì±…ë³„ë¡œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
4. ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°, ê°€ëŠ¥í•œ ë²”ìœ„ì—ì„œ ë‹µë³€í•˜ê³  ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•¨ì„ ëª…ì‹œí•´ ì£¼ì„¸ìš”.

### ì •ì±… [ë²ˆí˜¸]: [ì •ì±…ëª…]
- ìš”ì•½: [ìš”ì•½ ë‚´ìš©]
- ëŒ€ìƒ: [ëŒ€ìƒ ë‚´ìš©]
- ì§€ì›: [ì§€ì› ë‚´ìš©]
- ë°©ë²•: [ë°©ë²• ë‚´ìš©]
- ì£¼ì˜: [ì£¼ì˜ ë‚´ìš©]
- ë¬¸ì˜: [ë¬¸ì˜ ë‚´ìš©]

ë‹µë³€:"""
        )

        followup_prompt = PromptTemplate(
            input_variables=["selected_policy", "followup_question", "chat_history", "context"],
            template="""ë‹¹ì‹ ì€ í•œêµ­ ë³µì§€ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì •ì±…ì— ëŒ€í•´ ì‚¬ìš©ìê°€ í›„ì† ì§ˆë¬¸ì„ í–ˆìŠµë‹ˆë‹¤. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”.

[ì´ì „ ëŒ€í™” ê¸°ë¡]
{chat_history}

[ì°¸ê³ ìë£Œ]
{context}

[ì„ íƒëœ ì •ì±…]
{selected_policy}

[ì‚¬ìš©ìì˜ í›„ì† ì§ˆë¬¸]
{followup_question}

[ë‹µë³€ ì§€ì¹¨]
1. ì„ íƒëœ ì •ì±…ê³¼ ê´€ë ¨ëœ ì •ë³´ì— ì§‘ì¤‘í•˜ì—¬ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
2. í•„ìš”í•œ ê²½ìš° ì‹ ì²­ ì ˆì°¨, ëŒ€ìƒ ìš”ê±´, ìœ ì˜ì‚¬í•­ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•´ ì£¼ì„¸ìš”.
3. ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°, ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œ ë‹µë³€í•˜ê³  ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•¨ì„ ì•Œë ¤ ì£¼ì„¸ìš”.

ë‹µë³€:
"""
        )

        return {
            "policy": LLMChain(prompt=policy_prompt, llm=llm),
            "followup": LLMChain(prompt=followup_prompt, llm=llm)
        }

# =====================================================
# ì¿¼ë¦¬ ì²˜ë¦¬ í´ë˜ìŠ¤
# =====================================================

class QueryProcessor:
    @staticmethod
    def process_query(question, chat_name):
        """ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if st.session_state.get("retriever") is None or st.session_state.get("chains") is None:
            return "ë³µì§€ ì •ì±… ë¬¸ì„œì™€ AI ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.", []

        # ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì§€ì—­ ì¶”ì¶œ
        user_region = TextProcessor.find_region_in_text(question)

        try:
            # ë¬¸ì„œ ê²€ìƒ‰
            initial_docs = st.session_state.retriever.invoke(question)
        except Exception as e:
            return f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", []

        # ì§€ì—­ í•„í„°ë§
        docs = []
        for doc in initial_docs:
            doc_region = doc.metadata.get("region", "ì „êµ­")
            if (doc_region == user_region or doc_region == "ì „êµ­" or user_region == "ì „êµ­" or
                (user_region in SIDO_CITY_MAP.get(doc_region, []))):
                docs.append(doc)

        # ë¬¸ì„œ í’ˆì§ˆ ê²€ì¦
        quality_docs = []
        for doc in docs[:3]:
            cleaned_content = TextProcessor.clean_text(doc.page_content)
            if len(cleaned_content.strip()) > 30:
                quality_docs.append(doc)
                
        if not quality_docs:
            return """ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
                
ë” ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ì œê³µí•´ ì£¼ì‹œë©´ ë„ì›€ì´ ë©ë‹ˆë‹¤:
- êµ¬ì²´ì ì¸ ê±°ì£¼ì§€ì—­ (ì‹œ/êµ°/êµ¬)
- ë‚˜ì´ ë° ê°€êµ¬ í˜•íƒœ
- ì†Œë“ ìˆ˜ì¤€ ë° íŠ¹ë³„í•œ ìƒí™©
- ì°¾ê³  ê³„ì‹  ë³µì§€ ë¶„ì•¼ (ì£¼ê±°, ìœ¡ì•„, ì·¨ì—… ë“±)""", []

        # ì°¸ê³ ìë£Œ êµ¬ì„±
        context_parts = []
        search_results = []
        for i, doc in enumerate(quality_docs[:3]):
            clean_content = TextProcessor.clean_text(doc.page_content)
            context_parts.append(f"[ì°¸ê³ ìë£Œ {i+1}]\n{clean_content[:1000]}")
            
            source = doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
            page = doc.metadata.get('page', '')
            
            search_results.append({
                'content': clean_content[:500] + "..." if len(clean_content) > 500 else clean_content,
                'page': page,
                'source': source
            })

        context = "\n\n".join(context_parts)
        try:
            memory = MemoryManager.get_conversation_memory(chat_name)
            chat_history = memory.buffer
            
            # í›„ì† ì§ˆë¬¸ íŒë‹¨
            is_followup = FollowupHandler.is_followup_question(question, chat_history)
            
            if is_followup:
                selected_policy = FollowupHandler.extract_referenced_policy(question, chat_history)
                response = st.session_state.chains["followup"].run({
                    "followup_question": question,
                    "selected_policy": selected_policy,
                    "context": context,
                    "chat_history": chat_history
                })
            else:
                response = st.session_state.chains["policy"].run({
                    "question": question, 
                    "context": context,
                    "chat_history": chat_history
                })
            
            processed_response = TextProcessor.extract_answer_only(response)
            processed_response = TextProcessor.remove_emojis_and_special_chars(processed_response)

            # ë©”ëª¨ë¦¬ì— ì €ì¥
            memory.save_context({"question": question}, {"text": processed_response})

            return processed_response, search_results
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", []

    @staticmethod
    def generate_answer_streaming(question, chat_name):
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)."""
        try:
            response, search_results = QueryProcessor.process_query(question, chat_name)
            
            if not response or "ì˜¤ë¥˜" in response:
                yield response, [], []
                return
            
            words = response.split(' ')
            sources = []
            if search_results:
                for result in search_results:
                    source_info = f"{result['source']} (í˜ì´ì§€ {result['page']})"
                    sources.append(source_info)

            for i in range(0, len(words), 5):
                yield " ".join(words[:i+5]), sources, search_results
                time.sleep(0.1)
                    
        except Exception as e:
            yield f"ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [], []

# =====================================================
# UI ê´€ë¦¬ í´ë˜ìŠ¤
# =====================================================

class UIManager:
    @staticmethod
    def render_css():
        """CSS ìŠ¤íƒ€ì¼ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
        st.markdown(
            """
            <style>
            /* í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¡¤ ì‹œ ì±„íŒ… ì…ë ¥ì°½ì„ ìœ„í•œ ì—¬ë°± */
            .main .block-container {
                padding-bottom: 120px !important;
            }
            
            /* ë§ˆì´í¬ ë²„íŠ¼ ì •ë ¬ */
            .mic-button {
                display: flex !important;
                align-items: center !important;
                justify-content: center !important;
                height: 48px !important;
            }
            </style>
            """,
            unsafe_allow_html=True
        )

    @staticmethod
    def render_header():
        """í—¤ë”ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
        st.markdown(
            """
            <h1 style='text-align: center; font-size: 3.2em;'>ìƒì• ì£¼ê¸°ë³„ ê°œì¸ ë§ì¶¤í˜• ë³µì§€ ì¶”ì²œ AI ì—ì´ì „íŠ¸</h1>
            <p style='text-align: center; font-size: 1.5em; color: #555;'>
                ë‹¹ì‹ ì˜ ìƒí™©ì— ê¼­ ë§ëŠ” ë³µì§€ ì •ì±…ì„ <b>AI</b>ê°€ ì‰½ê³  ë¹ ë¥´ê²Œ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.<br>
                ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ì…ë ¥í•´ë³´ì„¸ìš”!
            </p>
            """,
            unsafe_allow_html=True
        )

    @staticmethod
    def render_usage_tips():
        """ì‚¬ìš© íŒì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
        if not st.session_state.get("chat_started", False):
            st.info("""
            ğŸ’¡ **ì‚¬ìš© íŒ**
            - êµ¬ì²´ì ì¸ ìƒí™©ì„ ì„¤ëª…í•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            - ì˜ˆì‹œ: "30ëŒ€ ì‹ í˜¼ë¶€ë¶€ë¥¼ ìœ„í•œ ì£¼ê±° ì§€ì› ì •ì±…ì„ ì•Œë ¤ì£¼ì„¸ìš”"
            - ë‚˜ì´, ì†Œë“, ê°€êµ¬ í˜•íƒœ ë“±ì˜ ì •ë³´ë¥¼ í•¨ê»˜ ì œê³µí•´ì£¼ì„¸ìš”
            - ì¶”ê°€ì ì¸ ë¬¸ì„œ(PDF)ë¥¼ ì—…ë¡œë“œí•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì„ íƒì‚¬í•­)
            - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì—°ì†ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤
            - **í›„ì† ì§ˆë¬¸**: ì •ì±…ì´ ì œì‹œëœ í›„ "1ë²ˆ ì •ì±…ì˜ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”", "ê·¸ ì •ì±…ì˜ ìê²© ìš”ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?" ê°™ì€ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            - ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ìƒˆ ì±„íŒ…ì„ ìƒì„±í•˜ê±°ë‚˜ ê¸°ì¡´ ì±„íŒ…ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
            """)

    @staticmethod
    def render_sidebar():
        """ì‚¬ì´ë“œë°”ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
        with st.sidebar:
            # ìƒˆ ì±„íŒ… ë²„íŠ¼
            if st.button("ğŸ“ ìƒˆ ì±„íŒ…", type="secondary", use_container_width=True):
                ChatManager.start_new_chat()
            
            st.divider()
            
            # ì±„íŒ… ëª©ë¡
            st.subheader("ì±„íŒ…")
            chat_list = ChatManager.get_chat_list()
            
            for i, chat in enumerate(chat_list):
                display_text = f"{chat[:20]}..." if len(chat) > 20 else chat
                
                if chat == st.session_state.current_chat:
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        st.markdown(
                            f'<div style="background-color: #444444; padding: 8px; border-radius: 8px; font-weight: bold; color: #FFFFFF; width: 100%;">'
                            f'{display_text}'
                            f'</div>',
                            unsafe_allow_html=True
                        )
                    with col2:
                        if len(chat_list) > 1:
                            if st.button("ğŸ—‘ï¸", key=f"delete_current_{i}", help="í˜„ì¬ ì±„íŒ… ì‚­ì œ", use_container_width=False):
                                ChatManager.delete_chat(chat)
                                st.rerun()
                else:
                    col1, col2 = st.columns([5, 1])
                    with col1:
                        if st.button(f"{display_text}", key=f"chat_{i}", use_container_width=True, help="ì±„íŒ… ì„ íƒ"):
                            st.session_state.current_chat = chat
                            st.session_state.chat_box.use_chat_name(chat)
                            st.rerun()
                    with col2:
                        if len(chat_list) > 1:
                            if st.button("ğŸ—‘ï¸", key=f"delete_other_{i}", help="ì±„íŒ… ì‚­ì œ", use_container_width=False):
                                ChatManager.delete_chat(chat)
                                st.rerun()
            
            st.divider()
            
            # ë¬¸ì„œ ìƒíƒœ
            UIManager.render_document_status()
            
            # ì¶”ê°€ ë¬¸ì„œ ì—…ë¡œë“œ
            UIManager.render_document_upload()

    @staticmethod
    def render_document_status():
        """ë¬¸ì„œ ìƒíƒœë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
        st.subheader("ë¬¸ì„œ ìƒíƒœ")
        pdf_dir = "./pdf/welfare"
        
        if st.session_state.get("default_documents_loaded", False):
            if os.path.exists(pdf_dir):
                default_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]
                st.success(f"âœ… ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œ {len(default_files)}ê°œ íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                with st.expander("ê¸°ë³¸ ë¬¸ì„œ ëª©ë¡ ë³´ê¸°"):
                    for file in default_files:
                        st.write(f"ğŸ“„ {file}")
            else:
                st.warning("âš ï¸ ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if os.path.exists(pdf_dir) and len([f for f in os.listdir(pdf_dir) if f.lower().endswith(".pdf")]) > 0:
                st.info("â³ ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...")
            else:
                st.warning("âš ï¸ pdf/welfare í´ë”ì— ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    @staticmethod
    def render_document_upload():
        """ë¬¸ì„œ ì—…ë¡œë“œ ì„¹ì…˜ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
        st.subheader("ì¶”ê°€ ë¬¸ì„œ ì—…ë¡œë“œ")
        
        uploaded_files = st.file_uploader(
            "ì¶”ê°€ ë³µì§€ ì •ì±… PDF íŒŒì¼ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒì‚¬í•­)",
            type=["pdf"],
            accept_multiple_files=True,
            help="ê¸°ë³¸ ë¬¸ì„œì— ì¶”ê°€ë¡œ ë” ë§ì€ ì •ì±… ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        if st.button("ì¶”ê°€ ë¬¸ì„œ ë¡œë“œ", type="secondary"):
            if uploaded_files:
                success = DocumentProcessor.load_additional_documents(uploaded_files)
                if success:
                    st.rerun()
            else:
                st.warning("ì—…ë¡œë“œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

# =====================================================
# í”¼ë“œë°± ì²˜ë¦¬
# =====================================================

def on_feedback(feedback, chat_history_id: str = "", history_index: int = -1):
    """í”¼ë“œë°±ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    reason = feedback.get("text", "")
    score = feedback.get("score", 0)
    
    if "feedback_history" not in st.session_state:
        st.session_state.feedback_history = []
    
    st.session_state.feedback_history.append({
        "chat_history_id": chat_history_id,
        "history_index": history_index,
        "score": score,
        "reason": reason,
        "timestamp": time.time()
    })
    
    st.session_state["need_rerun"] = True

# =====================================================
# ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# =====================================================

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í•¨ìˆ˜"""
    st.set_page_config(
        page_title="ìƒì• ì£¼ê¸°ë³„ ê°œì¸ ë§ì¶¤í˜• ë³µì§€ ì¶”ì²œ AI ì—ì´ì „íŠ¸",
        page_icon="ğŸ›ï¸",
        layout="wide"
    )
    
    # ì´ˆê¸°í™”
    if "chat_box" not in st.session_state:
        st.session_state.chat_box = ChatBox(
            use_rich_markdown=True,
            user_theme="green",
            assistant_theme="blue",
        )
        st.session_state.chat_box.use_chat_name("welfare_chat")
    
    if "current_chat" not in st.session_state:
        st.session_state.current_chat = "welfare_chat"
    
    if "mic_active" not in st.session_state:
        st.session_state.mic_active = False
    
    chat_box = st.session_state.chat_box
    
    # ê¸°ë³¸ ë¬¸ì„œ ë¡œë“œ
    DocumentProcessor.load_default_documents()
    
    # UI ë Œë”ë§
    UIManager.render_sidebar()
    UIManager.render_header()
    UIManager.render_usage_tips()
    
    # ì±„íŒ… ìƒíƒœ í™•ì¸
    if len(st.session_state.chat_box.history) > 0:
        st.session_state.chat_started = True
    
    # ì±„íŒ… ë°•ìŠ¤ ì„¤ì •
    chat_box.use_chat_name(st.session_state.current_chat)
    st.markdown('<div class="chat-history-container">', unsafe_allow_html=True)
    chat_box.init_session()
    chat_box.output_messages()
    
    feedback_kwargs = {
        "feedback_type": "thumbs",
        "optional_text_label": "í”¼ë“œë°±ì„ ë‚¨ê²¨ì£¼ì„¸ìš”",
    }
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # CSS ì ìš©
    UIManager.render_css()
    
    # ì±„íŒ… ì…ë ¥ì°½
    col1, col2 = st.columns([8, 1])

    with col1:
        current_chat = st.session_state.current_chat
        history = MemoryManager.get_conversation_history(current_chat)
        is_first_question = len(history) == 0 and len(st.session_state.chat_box.history) == 0

        placeholder_text = ("ë³µì§€ ì •ì±…ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”. (ì˜ˆ: 30ëŒ€ ì‹ í˜¼ë¶€ë¶€ ì£¼ê±° ì§€ì› ì •ì±…)" 
                          if is_first_question 
                          else "ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        st.markdown('<div style="height: 48px; display: flex; align-items: center;">', unsafe_allow_html=True)
        query = st.chat_input(placeholder_text)
        st.markdown("</div>", unsafe_allow_html=True)

    with col2:
        st.markdown('<div class="mic-button" style="height: 48px; display: flex; align-items: center; justify-content: center;">', unsafe_allow_html=True)
        if st.button("ğŸ¤", key="mic_button", type="secondary" if not st.session_state.mic_active else "primary"):
            st.session_state.mic_active = not st.session_state.mic_active
            st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)
        
    # ì±„íŒ… ì…ë ¥ ì²˜ë¦¬
    if query:
        if not st.session_state.get("default_documents_loaded", False) or "chains" not in st.session_state:
            st.error("â³ ê¸°ë³¸ ë³µì§€ ì •ì±… ë¬¸ì„œì™€ AI ëª¨ë¸ì„ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!")
            return
        
        current_chat = st.session_state.current_chat
        
        # ì±„íŒ… ì´ë¦„ ìë™ ìƒì„±
        if (current_chat == "welfare_chat" and 
            len(MemoryManager.get_conversation_history(current_chat)) == 0 and
            len(st.session_state.chat_box.history) == 0):
            
            chat_name_preview = query[:20] + "..." if len(query) > 20 else query
            chat_name_preview = re.sub(r'[^\w\sê°€-í£]', '', chat_name_preview)
            
            if "welfare_chat" in st.session_state.chat_list:
                index = st.session_state.chat_list.index("welfare_chat")
                st.session_state.chat_list[index] = chat_name_preview
                st.session_state.current_chat = chat_name_preview
                current_chat = chat_name_preview
        
        chat_box.use_chat_name(current_chat)
        chat_box.user_say(query)
        
        try:
            elements = chat_box.ai_say(["ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...", ""])
            generator = QueryProcessor.generate_answer_streaming(question=query, chat_name=current_chat)
            
            text = ""
            sources = []
            search_results = []
            
            try:
                for response, doc_sources, doc_search_results in generator:
                    text = response
                    sources = doc_sources
                    search_results = doc_search_results
                    chat_box.update_msg(text, element_index=0, streaming=True)
            except Exception as e:
                text = f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                sources = []
                search_results = []
            
            chat_box.update_msg(text, element_index=0, streaming=False, state="complete")
            
            # ì°¸ê³ ìë£Œ í‘œì‹œ
            reference_text = ""
            if search_results:
                reference_text += "ê²€ìƒ‰ëœ ê´€ë ¨ ì •ë³´:\n\n"
                for i, result in enumerate(search_results, 1):
                    reference_text += f"{i}. {os.path.basename(result['source'])} (í˜ì´ì§€ {result['page']})\n"
                    reference_text += f"{result['content']}\n\n"
                reference_text += "---\n\n"
            
            if sources:
                reference_text += "ì°¸ê³ ìë£Œ:\n" + "\n".join(sources)
            else:
                reference_text += "ì°¸ê³ ìë£Œ: ì—†ìŒ"
            
            chat_box.update_msg(reference_text, element_index=1, streaming=False, state="complete")
            
            # í”¼ë“œë°±
            chat_history_id = f"chat_{len(chat_box.history)}"
            chat_box.show_feedback(
                **feedback_kwargs,
                key=chat_history_id,
                on_submit=on_feedback,
                kwargs={"chat_history_id": chat_history_id, "history_index": len(chat_box.history) - 1}
            )
            
        except Exception as e:
            chat_box.ai_say([f"ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì˜¤ë¥˜: {str(e)}", "ğŸ“„ ì°¸ê³ ìë£Œ: ì—†ìŒ"])

if __name__ == "__main__":
    main() 